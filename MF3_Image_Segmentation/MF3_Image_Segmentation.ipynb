{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2d0dfe",
   "metadata": {},
   "source": [
    "# MF3 Image Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35704865",
   "metadata": {},
   "source": [
    "## 368 Image Segmentation\n",
    "\n",
    "In this lecture, we'll look at an application of max flow to a problem from computer vision, known as Image Segmentation. We're given an image, such as this one, and our goal is to separate the image into objects. The easier tests that we're going to look at is to simply separate the image into foreground and background. For example, in this image we want to discern the triangle from the rest of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185a59f3",
   "metadata": {},
   "source": [
    "## 369 Formulation\n",
    "\n",
    "We are going to view the images lying on a graph with the vertices of a graph correspond to the pixels of the image. So let us look at an example of a pixelated image. Here is an example of a small pixelated image magnified. The input is going to be specified by an undirected graph G. The vertices of the graph once again correspond to the pixels of the image. So there are nine vertices in this example and the edges will go between neighboring pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3f6434",
   "metadata": {},
   "source": [
    "## 370 Parameters\n",
    "\n",
    "The input once again is specified by an undirected graph G where the vertices correspond to the pixels. And in addition, we have the following parameters; for each pixel, we have two parameters, fi and bi. Fi is the likelihood or weight that vertex i, pixel i is in the foreground. And bi is the weight or likelihood that pixel i is in the background. Now, we'll assume that both of these parameters are non-negative. In addition, we're given a parameter for each pair of neighboring pixels. Pij is a separation penalty for this edge. It's the cost of separating i and j into different objects. And once again, we'll assume that pij is not negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c201e586",
   "metadata": {},
   "source": [
    "## 371 Example\n",
    "\n",
    "This is our example of an image from before. Let's look at an example setting of the parameters in this case. Here are example settings for the foreground and background likelihood for this image. So we're saying that the white pixels are more likely to be in the foreground and the black pixels are more likely to be in the background. For this image, we could have just as well reversed what we called foreground and background since we've defined the matrix to be symmetric. And here are sample separation penalties. And when the pixels are different, we don't pay any penalty for separating the pixels into different objects. Now keep in mind, this is very much a toy example. All the pixels are monochromatic. So we've chosen very simple weights in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c018802",
   "metadata": {},
   "source": [
    "## 372 Partition\n",
    "\n",
    "Our goal is to partition the vertices of pixels into two sets F and B. F will correspond to the foreground pixels and capital B will be the pixels that we assign to the background. Now, for a particular partition B, we need some score or weight to measure the likelihood of this partition. Thus, we defined the weight of this partition as the following for each pixel assigned to the foreground we get FB for each pixel assigned to the background we get BJ have used different indices for these two sets to avoid some confusion. Finally, we pay a separation penalty for separated edges. This is a penalty so we're going to subtract it. And, we're going to look at all edges where the first endpoint is an F and the other end point is in B or vice versa. And, the penalty is of course CIJ. This defines the weight for a particular partition FB. So, for a particular assignment of the pixels to foreground and background we have a weight associated with it. Our goal is to find the partition or assignment of pixels to foreground and background with maximum weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f322322",
   "metadata": {},
   "source": [
    "## 373 Min Cut\n",
    "\n",
    "Now our goal is to reduce this problem, this maximisation problem, to the min st-cut problem. So we have to somehow change this maximisation problem into a minimization problem. So we are going to have to modify these weights. And the other issue is that we are summing some terms and we are subtracting other terms. Now all of these parameters are non-negative. In our min st-cut problem, all the capacities in the input flow network are all positive. So we somehow need to change this minus of the separation penalty into an addition, so that all the terms are positive or non-negative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9079cf83",
   "metadata": {},
   "source": [
    "## 374 Reformulation\n",
    "\n",
    "Look at the sum of all the foreground and background likelihoods. So, let capital L denote the sum over all pixels of their foreground likelihood plus their background likelihood. We color our weight for a particular partition FB at weight fi for each pixel assigned to the foreground, and bj for each pixel assigned to the background. Notice, that this quantity is equal to capital L minus the sum of the pixels assigned to the foreground of their background, minus the sum of all the pixels assigned to the background of their foreground. Because, if we take the sum over the pixels assigned to the foreground of their foreground likelihood, plus sum of the pixels assigned to the background of their foreground likelihood, we get the total likelihood of all pixels for the foreground. This is the first term in this sum. Simply by summing this term with this term, we get this total likelihood of all pixels for the background. Now, if we subtract a separation penalty for separated edges, now think of this ij as an un-ordered pair. So, I don't have to write both cases, i and F, or j and B, this un-ordered pair that covers the other case, where i is in B, and j is an F. Now, to maintain equality, I want to subtract this term also from the other side. Now, what do you notice about this left hand side? Well, this is exactly our definition of the weight, W of FB. Now, we're going to define a new weight W-prime of FB, which is the sum of these three terms, and then the right hand side will be equal to L, capital L minus W-prime of FB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40243a",
   "metadata": {},
   "source": [
    "## 375 New Weights\n",
    "\n",
    "Now just to summarize we let capital L be the sum of the foreground and background likelihoods for all pixels. Now for a partition F, B we define its weight to be the following quantity: it's a sum over the vertices assigned to the foreground of their foreground likelihood plus the pixels assigned to the background of their background likelihood minus the separation penalty for separated edges. Now let's define a new weight W prime. This is the sum over vertices assigned to the foreground of their background likelihood plus the sum over vertices assigned to the background of their foreground likelihood. And now we'll add instead of subtract the separation penalty and the key point is that these two quantities are related in the following manner, W_F,B equals L minus W'_F, B. The separation penalty's cancel from both sides and then when you add up these remaining terms you get L. Now the point is if we find the partition F, B which maximizes the weight W of F, B this is equivalent to finding the partition F, B which minimizes W'. Since we're subtracting off W' minimizing this term is the same as maximizing the whole quantity. So we've changed our maximization problem into a minimization problem and all the terms and W prime are positive. So now this is in potential form that we can convert it to a mean SD cut problem. And how do we solve the mean SD card problem? We solve it by doing the max flow problem. So we're going to find a flow networks, solve the max flow on that flow network and then that will give us the mean SD cut solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f34cb4",
   "metadata": {},
   "source": [
    "## 376 New Problem\n",
    "\n",
    "Here is our new problem formulation. The input is an undirected graph corresponding to the image, once again, and we're given the following weights. For each pixel, for each vertex I, we're given fi and bi and these are non-negative weights. And, for each edge, we are given the weight Pij, which is also non-negative. And, our goal is to find the partition of the vertices or pixels into two sets, F and B, and we want the partition which minimizes the weight, w prime of FB. Recall the partition, FB, which minimizes w prime of FB, is the same partition which maximizes w of FB and therefore it solves the original image segmentation problem. Now, let's see how to reduce this to the max flow problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761ced0",
   "metadata": {},
   "source": [
    "## 377 Flow Network\n",
    "\n",
    "To convert this new image segmentation problem into a max-flow problem, we define the flow network which is the input to our max-flow problem. Now, the input to the image segmentation problem is undirected graph. Now flow network is a directed graph. So we have to take this undirected graph and define a directed graph G-prime. Now, here's our example input to the image segmentation problem. This corresponds to a natural undirected graph which is the corresponding directed graph. Well, here are the vertices of this graph. And instead of putting undirected edges between neighboring pixels, we'll put bi-directional edges. So these bi-directional arrows denote edges going from this pixel to this pixel and vice versa. This pixel back to this pixel. So this is the directed graph corresponding to our undirected image. So for each edge in our undirected graph, we add an edge from i to j and j to i. Now, what are the capacities on these edges? Well, we want to keep track of the separation penalties, so it's natural to put capacities which are the separation penalties. So both of these edges will get capacity Pij. Now, that encodes the separation penalties. What do we do with the foreground and background likelihoods? Well, we're going to add additional vertex corresponding to the foreground and an additional vertex corresponding to the background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30331b70",
   "metadata": {},
   "source": [
    "## 378 Foreground\n",
    "\n",
    "So, we're going to add a vertex S, a source vertex, corresponding to the foreground pixels. Now, here's the same directed graph, once again, with the vertices shrunk a little bit, just for illustrative purposes. Now, we're going to add two additional vertices, S and t. S will correspond to the foreground, t will correspond to the background, and this will be our source and our sync for our max-flow problem. We're going to add an edge from S to every pixel, every vertex. So, for every pixel in the original undirected graph, we add an edge from S to i. Now, S is supposed to correspond to the foreground. So, the capacity of this edge will be fi. So, we encode the foreground likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1275799d",
   "metadata": {},
   "source": [
    "## 379 Background\n",
    "\n",
    "Now for the background, we do similar, using this vertex t. So, we have an edge from every vertex of the original undirected graph to t. So these edges are going to T, whereas edges came out of S. So S was a source and T is a sync, and the capacity of these edges two t will be the background likelihood. So now we've got the foreground likelihood and the background likelihood encoded, and we have the separation penalties encoded. So here's our final graph, and we've specified the capacities along every edge. Therefore, we've defined a flow network, and we can use this as our input to the max-flow problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd93b0",
   "metadata": {},
   "source": [
    "## 380 Cuts\n",
    "\n",
    "Now we're going to take this flow network, and we're going to run the max-flow on it. We're going to get a flow of maximum size, and we know that the size of the maximum flow equals the capacity the minimum S, T cut. Now let's try to understand S, T cuts. For a particular partition F, B, what is the capacity of that cut? Recall the capacity of this cut, and the capacity of the edges that go from F to B. So which S go from F to B? Recall we only get these edges that go from F to B. We don't get the edges that go from B to F. So let's define a partition or cut in this graph. Let's suppose that these four pixels get assigned to the foreground. So this is our set F, and the remaining five, six vertices are in the background B. Now which edge is cross from F to B? Now consider one of these four pixels in the foreground. Notice its edge to T, crosses this cut. So we get this edge from I to T, and what's the capacity of this edge? It's B, I. That was our definition of this flow network. Similarly, look at these pixels assigned to the background. For each of these five pixels, we get the edge from S to that pixel, and that edge from S originates in F, and ends in B. So it crosses this cut from F to B. And what's the capacity of this edge from S to this pixel? And that was defined to be F, J. Finally, for each of these separated edges, we get the edge in one direction, but not the other direction. We get this edge, this edge, this edge, and this edge. But notice we don't get the other direction edge. So for each edge in the original undirected graph, if I is assigned to the foreground, and J is assigned to the background, then we get the edge from I to J, and the capacity is P, I, J. Now if you sum up these terms, what do you get? That's the capacity of this cut, F, B. And that's exactly equal to W prime of F, B. That was our definition of W prime. We summed over pixels in the foreground of B, I. Pixels in the background of F, J, and the separation penalty. That's great. Our capacity is exactly equal to the quantity W prime, and our goal was to minimize W prime. If we run max-flow, we find a mins S, T cut. That's a cut with minimum capacity. So, we found the cut, the partition which minimizes W prime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d7a5e",
   "metadata": {},
   "source": [
    "## 381 Solution\n",
    "\n",
    "So, we can summarize our solution to the image segmentation problem. Given our original input to the image segmentation problem, this consists of an undirected graph corresponding to the image, the foreground likelihoods, background likelihoods, and the separation penalties. Then we define a flow network. This consists of a directed graph. We take this undirected graph, make each edge bi-directional, and then we add s, which directs to every vertex in the original undirected graph. And, we add vertex t, which has an edge from every pixel in the original undirected graph, to t that defines the directed graph, and then we define our capacities. Then we run max flow on this flow network, and we get a flow, f* of maximum size. Now, the size of this max flow, equals the capacity of the min st-cut, this is the max flow min-cut theorem. And in fact, we can take this max flow and construct a cut of minimum capacity. And, we just saw that the capacity of a particular st-cut equals the weight, w prime of FB. Therefore, by finding the cut of minimum capacity, it's equivalent to finding the partition of minimum weight w prime. Now, our original problem was to find the partition of maximum weight, w. Well, this is the same as capital L, this normalizing factor, minus the min over partitions of w prime. So, if we find the partition which minimizes w prime, that's the same partition which maximizes w. And therefore, we've shown how to solve the original image segmentation problem using the max flow problem."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
