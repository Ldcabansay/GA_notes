{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515f9e01",
   "metadata": {},
   "source": [
    "# GR1 Strongly Connected Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe257be",
   "metadata": {},
   "source": [
    "## 251 Graph Algorithms\n",
    "\n",
    "The next section is about graph algorithms. I'm sure you've all seen the basic graph algorithms before; DFS for depth-first search, BFS for breadth-first search and Dijkstra's single source shortest path algorithm. We'll do a quick review of how DFS is used to find the connected components of an undirected graph, and then we'll build on that to look at connectivity in directed graphs. We'll use DFS to find the strongly connected components of directed graphs. These are the analog of connected components in directed graphs. And then we'll see an application of our strongly connected component algorithm to solve the two set problem. Next, we'll look at the minimum spanning tree problem, MSTs. You've likely seen that Kruskal's and Prim's algorithm before for finding an MST. We'll look at the correctness behind these algorithms. Finally, we'll look at the PageRank algorithm. This is the algorithm that looks at the Web graph and assigns weights to vertices or webpages. It's a measure of their importance. This algorithm was devised by Brin and Page, and it's at the heart of Google's search engine. To understand the PageRank algorithm, I'll first give you a quick primer on Markov chains, and then you'll see how it relates to strongly connected components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3ef60",
   "metadata": {},
   "source": [
    "## 252 Outline\n",
    "\n",
    "In this lesson, we're going to look at connectivity algorithms using algorithms based on DFS. DFS of course, refers to depth-first search. We'll start off by reviewing DFS for undirected graphs and look at the algorithm for determining connected components and undirected graphs. That algorithm is probably familiar to many of you. After that, we'll look at DFS for directed graphs and our goal is to determine the analog of connected components for directed graphs. We begin by looking at DAGs. DAGs are directed acyclic graphs. Acyclic means that it has no cycles. We'll see how the topologically sort DAGs. What this means is that, we can order the vertices, say from left to right, so that all edges go left to right. Now, this algorithm may be familiar to many of you, but we'll use it to derive some intuition for our more sophisticated algorithms for general directed graphs. For general directed graphs, we are going to be looking to find the SCCs. These are the strongly connected components. This is the analog of connected components for directed graphs. The algorithm for finding SCCs is really sweet. It's just two DFS. Actually, it's the same DFS algorithm we found before for undirected graphs and we just run it two times and we'll find this strongly connected components of any directed graph. Now, it's a very simple algorithm but we're going to get there a bit slowly. We're going to go through all of these steps in order to derive some intuition before we get to this more general algorithm for general director graphs. So let's start with undirected graphs and let me remind you about the DFS algorithm that you've probably seen a million times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11764e13",
   "metadata": {},
   "source": [
    "## 253 Undirected Graphs\n",
    "\n",
    "For a given undirected graph, how do we find it's connected components? Well, we simply run DFS and we keep track of the component number. So, each vertex is going to have its component number stored. Let me remind you of this pseudocode for DFS, because we're going to make some tweaks to it during the course of this lecture. So, the DFS algorithm takes as input a graph, G. For now, let's think of G as an undirected graph. But later, we're going to run the same algorithm on a directed graph and it's going to be identical pseudocode. And we assume that the graph is given to us in adjacency list representation. And for now, we're looking at connected components of undirected graph. So, the vertices are going to be labeled by a connected component number. We're going to have a counter which is the current connected component number. We're going to have an array which keeps track of whether we visited a vertex yet or not, and we're going to start off by initializing the visited array to false for all vertices of the graph. Now, we go through the vertices in an arbitrary order. Now, if we get to a vertex that we haven't visited yet, what do we do? Well, this means that we found a new connected component. So, we increment the connected component number and then we start exploring from this vertex. And let's now look at the subroutine for explore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b1d61",
   "metadata": {},
   "source": [
    "## 254 Exploring Undirected Graphs\n",
    "\n",
    "Now let's look at the pseudocode for the Explore procedure, and let's say we're running Explore from a vertex Z. This is our first time visiting Z. So we have to store its connected component number as the current count for the connected components, and we have to set Z to be visited. Now, we want to explore all edges out of Z. Recall that G was given to us an adjacency list representation, so now we can look through the linked list of neighbors of Z. Now for a particular neighbor W, if W hasn't been visited yet then we recursively explore from W and we repeat this procedure. Now what's a running time of this algorithm? Hopefully, you recall that DFS is a linear time algorithm. So the running time is O(N + M). For undirected graphs, this is it, this gets all the information that we're trying to glean, the connected components of the graph. Now we're going to turn to directed graphs and we're going to need more information from our DFS in order to obtain connectivity information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64494f43",
   "metadata": {},
   "source": [
    "## 255 DFS Paths\n",
    "\n",
    "We saw in the last slide how to use the DFS algorithm to find the connected components of an undirected graph. Before we move on to directed graph, let's gleam a little bit more information from the DFS algorithm. In particular, suppose I have a pair of vertices, v and w which are in the same connected component. I want to find a path between this pair of vertices. To do that, we simply have to keep track of the predecessor Vertex when we first visit a vertex. Here's the DFS algorithm once again for finding connected components of an undirected graph. We're going to use this previous array as is used in Dijkstra's algorithm to keep track of the predecessor Vertex. We initialize this previous array to null for every vertex. And when we first visit a vertex. So at this point in the algorithm, we should set its previous array to its predecessor Vertex, which is Vertex Z. So, we set previous W to Vertex Z. Now, after running DFS algorithm, given this previous array, we can use this previous array to backtrack. So, for a pair of vertices which are in the same connected component, we can use the previous array to find a path between this pair of connected vertices. That completes our discussion of DFS algorithms for undirected graphs. Let's move on now to directed graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8166ace",
   "metadata": {},
   "source": [
    "## 256 DFS on Directed Graphs\n",
    "\n",
    "We saw how to determine the connected components for an undirected graph, now let's take a look at directed graphs. How do we determine the connectivity properties for a directed graph? Once again we're going to use a DFS based approach, but now for directed graphs, we're going to need additional information from the DFS. The additional info that we use are the preorder or postorder numbers for the tree or forest of explorer the edges. The algorithm is going to be a slight variant of DFS that we saw just before, so let's look at that previous algorithm and just modify it a little bit. Here's a DFS algorithm for figuring out the connected components of an undirected graph. Our basic algorithm is going to be the same, but we no longer need to keep track of the connected component number, so let's remove those lines. This line, this line and this line. We can drop these three lines. So I've removed those three lines which talked about the connected component number. Now I want to add in lines which take care of the preorder and postorder numbers. In order to keep track of the preorder and postorder numbers, we're going to add in the clock. The preorder number for a vertex Z, is going to be the value of the clock when we first visit vertex Z, and the postorder number is going to be the value of the clock at the time when we finished exploring vertex Z. So we looked at all edges out of Z. First we need to initialize the clock to one. When we first visit a vertex Z, we can store as preorder number, which is the current value of the clock. After we do this, we need to increment the clock. Finally when we finish exploring vertex Z, then we can set its postorder number to be the current value of the clock. And then once again we have to increment the value of the clock. That gives as DFS undirected graphs. Now we want to see the properties of these preorder and postorder numbers. And actually for our connectivity algorithms, we're simply going to use the postorder numbers. And to be perfectly honest, I'm not even sure where preorder numbers come into play. The only application I know of for preorder numbers are in order to try to trick you on exams or homeworks. But just in case I kept the preorder number in here in the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7b5d9e",
   "metadata": {},
   "source": [
    "## 257 Directed DFS Example\n",
    "\n",
    "Here's an example of a specific directed graph on eight vertices. Now lets run our DFS algorithm for directed graphs on this specific example starting at the vertex B. And for concreteness we'll assume that the linked lists are stored in alphabetical order. So when we look at the edges out of B for example, we're going to see A and C then E. And let's look at the tree of explored edges in our DFS run. We're going to start at the vertex B, so this is going to be the root of the tree. And let's keep track of the pre-order and post-order numbers of the vertices as they are stored. We start exploring from B, so it gets a pre-order number. We first see neighbor A of vertex B. So the next edge that we explore is the edge B to A. We then assign of pre-order number to A. We then see vertex D and we give it its pre-order number. Then exploring from vertex D we see vertex E and then from vertex E we see vertex G. G gets pre-order number five. But notice from G there's nothing to explore. So we're going to pop back up from G back up to E. So we're going to finish exploring from G so we can give it post order number six. Now notice from Vertex E when we do explore from E, it was in an an edge from E to A. A has already been explored, has already been visited at that time. So we're not going to rerun explorer from A. This is not an edge in the DFS tree in the sense that A has already been explored at this time. So we're not going to rerun explorer from A but let's keep track of this edge and mark it as blue edge in order to distinguish it from the explored edges which are marked as black. After we've explored the two edges out of E to A and to G then we're going to pop back up to Vertex D. But first we're going to assign a post order number to E. Now from D we're going to see this edge to H, so we're going to explore from H. Now from H we see this neighbor G. G has already been visited, so let's mark this edge from H to G as a blue edge. Then we're going to finish exploring from H and we're going to pop back up to D. Lets assign its pre or post order numbers. From D there was an additional edge to G. Then we can assign its post order number and pop back up to A. A is done and then we can pop back up to B. From vertex B we're going to see vertex C and then F, so we're going to get this right sub-tree. Now from F we're going to see this edge back to B, that's a blue edge, and we're going to see this edge across to H and we can send the pre-order post-order numbers. And that completes the DFS run for this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae9405",
   "metadata": {},
   "source": [
    "## 258 Types of Edges\n",
    "\n",
    "Now let's look at a specific edge of the graph. Let's say goes from vertex z to vertex w. Now, that edge is going to appear in this graph over here of the DFS tree. It's either going to appear as a black edge, an explored edge, or as a blue edge. Let's look at the properties of this edge based on whether it's a black edge or it's a blue edge and what type of blue edge. Now, the black edges correspond to explored edges or edges of this tree, this DFS tree. Notice in this example, the DFS tree happened to be a tree. Every vertex happens to be reachable from the vertex B. It doesn't have to be the case. It could be a forest. We could have multiple components here. So, actually this should be called forest edges, but let's ignore that. We call this a DFS tree, even though it might be a forest. Some examples of these tree edges are B to A, A to D, and so on. All of the black edges are tree edges. Now, let's look at the properties of the post order numbers for these tree edges. Let's take the example of A to D. So we started exploring from A. Then we saw this neighbor D. So we recursively started exploring from D. We're going to finish off D, and assign a post order number, and then we're going to pop back to A. So, A is going to finish after D. So, the post order number of A is going to be bigger than the post order number of D, because it's going to finish later. And in general, the post order number of the head of this edge is going to be bigger than the post order number of the tail of this edge if it's a tree edge. Now, let's look at the blue edges. There's going to be three types of blue edges. Back edges, forward edges, and cross edges. The examples of back edges in this graph are E to A and F to B. The edge goes from a descendant to an ancestor. So, these are edges that go back up the tree. Now, let's take a specific example. Let's say E to A. Notice we're going to finish off E before we finish off A. So, in this case, the post order number of E is going to be smaller than the post order number of A. And in general, for back edges, the post order number of the head of the edge is going to be smaller than the post order number of the tail of the edge. This is opposite for the case of the tree edges. Now, let's look at forward edges. These are going down the tree. For example D to G. Another example of a forward edge is this edge, B to E. I forgot to notice this edge earlier when we were running DFS on our earlier example. Now what do you notice about the post order numbers for forward edges? Well, these behave just like tree edges. Tree edges are going down one depth. Forward edges are going down multiple depths. But, they have the same key property, that the post order number goes down. Finally, we have cross edges. For example, F to H and H to G. These are pairs of vertices that have no ancestor descendant relation to each other. Look at this edge from F to H. H must have been explored before F. Otherwise, H would be in the sub tree of F. Since this is an unexplored edge, that means that H was finished first, so the post order number of H is going to be smaller than the post order number of F. So, once again, the post order number goes down with the edge. Now, the key property is that for back edges, the post order number goes up. For all other edges, the other three types of edges, tree edges, forward edges, and cross edges, the post order number goes down. Now, that is the key property that we need for post order numbers. Back edges behave differently than the other three types of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d107014d",
   "metadata": {},
   "source": [
    "## 259 Cycles\n",
    "\n",
    "Now, let's look at properties of the graph and how these properties manifest themselves in the DFS tree. Let's look now at cycles. How does the cycle manifest itself in the DFS tree? The key property is that graph G has a cycle, if and only if, it's DFS tree has a back edge. Now, this doesn't matter where we start the DFS. What is the starting vertex? It doesn't matter how the vertices are ordered in the adjacency list representation also. For any start vertex, for any ordering on the vertices, for any ordering on the neighbors of every vertex, the DFS tree will contain a back edge, if and only if, G has a cycle. So, if there is a cycle, there will be a back edge that will appear in our DFS tree. And if the DFS tree contains a back edge, then there is a cycle in the graph. Let's see why this property holds. This is an equivalence relation. So let's look at the two implications. Let's look at first at the forward implication. Let's suppose that G has a cycle and let's see how a back edge appears. Let's suppose the graph G has a cycle and let's label the vertices of that cycle as a, b, c, up to j. So, there's an edge from a to b, b to c, up to j, and then back to a. Now, one of these vertices has to be explored first. There always has to be somebody first. So, let's say the first vertex is vertex i. So, what do we know then about our DFS tree? We know we have this vertex i. And now if we look at the sub-tree of i, we know that all these other vertices of the cycle are reachable from i. So, they're all going to lie in the sub-tree rooted at i. So, all the other vertices of the cycle are going to be contained in this sub-tree rooted at i. We don't know anything else about the structure of this sub-tree, we just know that this sub-tree contains all the other vertices of this cycle because they're all reachable from vertex i. Now at least one of these vertices has an edge to i. In this case, we know that i - 1 has an edge to i. This edge is going to appear as a back edge because it goes from a descendant to an ancestor. So we're going to have a back edge from i minus one to i. Now, let's look at the reverse implication. Let's suppose that our DFS tree has a back edge and let's prove that the graph then must contain a cycle. Let's say there is a back edge from vertex a to vertex b. So, what do we know? We know that vertex a is a descendant of vertex b, and there's this back edge from a to b. But since a is a descendant of b in this DFS tree, we know there's a sequence of tree edges which go from b down to a. And notice we now have our cycle. These tree edges are edges in the graph and then this back edge is also the edge of the graph. So, we have our cycle from b down to a and then back to b. That shows that there is a cycle. For every back edge, there is a cycle. That proves this property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769beb7",
   "metadata": {},
   "source": [
    "## 260 Toplogical Sorting\n",
    "\n",
    "Now let's take a look at DAGs. These are directed acyclic graphs. Acyclic means that there are no cycles in the graph. What we just saw is that the graph has a cycle if and only if the DFS tree has a back edge. Since there are no cycles, there's going to be no back edges in our DFS tree. Now what we're going to try to do is, we're going to try to top allegedly sort that DAG. What does that mean? We're going to order the vertices so that all edges go from lower order number vertex to a higher order number of vertex. So for instance, if we write down the vertices in order from lowest to highest, then all edges are going to go from left to right. We're not going to have any edges going backwards. To topologically sort this DAG, what we're going to do is, we're just going to run DFS on this DAG. What is the key property we know for this DAG? We know it has no back edges. What do we know about the post order numbers for all other types of edges? We know that for back edges, the post order number increases along the edge. For all other types of edges, the post order number goes down along the edge. Now we want to order the vertices from lowest to highest so that all edges go left to right. So which vertex do we want to put first? We want to put the vertex with highest post order number first and therefore all edges are going to go from higher post order number to lower post order number, because there are no back edges. Just to summarize, we know for every edge of the graph. So for instance this edge from Z to W. We know that the post order number of Z is greater than the post order number of W. So in order to topologically sort the graph, we order the vertices by decreasing post order number. The highest post order number comes first and the lowest post or number comes last. So in order to top logically sort a DAG, we just have to do one run of DFS and then sort by decreasing post order number. Now how long does it take us to sort by decreasing post order number? Now you might think this is order n log n time, because we have to do sorting. Now what is the range of these post order numbers? Where the clock starts at one, so all the post order numbers are at least one. How large can the post order number be? Or the maximum imposed order number is going to be two times n so all the post order numbers range between one and 2n. So what can you do? You can make an array of size 2n. Now we can go through the vertices, take their post order number and insert them into the appropriate place in the array based on their post order number. Now we go through this array from highest to smallest and we just output the vertices as we see them. This gives us the vertices in decreasing order of post order number. How long does this take to construct? Just takes linear time. So it takes order n time to sort the vertices by decreasing post order numbers and takes linear order n plus M time to run DFS. So the total algorithm takes order N plus M time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d4cf4",
   "metadata": {},
   "source": [
    "## 261 Topological Ordering Quiz Question\n",
    "\n",
    "Now here's an example of a graph on five vertices. Why don't you go ahead and give a topological ordering for this graph. There are five vertices, so let's write down the vertices in order so that all edges go from left to right. Now this graph happens to have multiple topological orderings. How many topological orderings does it in fact have? To make sure you understand topological orderings, why don't you go ahead and specify the number of topological orderings which are valid for this graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487bbe1d",
   "metadata": {},
   "source": [
    "## 262 Topological Ordering Quiz Solution\n",
    "\n",
    "Now here is one valid topological ordering, X, then Y, then Z, then U, then W. Notice that all the edges go left to right. Now how many valid topological orderings are there? Well, I can move U to any of these last three positions. So there are three choices for the position of U. After I specify the position for U, then the position for Z and W are forced because Z has to come before W. So this graph has three topological."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871c940",
   "metadata": {},
   "source": [
    "## 263 DAG Structure\n",
    "\n",
    "Now let's take a look at some properties of a DAG that we can derive from this topological ordering. Now there are two types of vertices we want to distinguish, source vertices and sink vertices. A source vertex has no incoming edges. So everything goes out of a source. For a sink vertex. It's the opposite. Nothing comes out of sink. Things only come into a sink. Now a DAG always has at least one source and at least one sink. There may be multiple sources, there may be multiple sinks. But we're always guaranteed there's at least one source and at least one sink. How do we know that there's a source vertex in every DAG? We'll take any topological ordering and look at the first vertex, in this case x. What do we know about x? We know all edges in the topological ordering go from left to right, from earlier in the topological ordering to later. So edges can only come out of the first vertex in the topological ordering. No edges can come in, because then they would come from right to left. So every DAG has a topological ordering, the first vertex in every topological ordering must be a source vertex. So that guarantees that every DAG has at least one source vertex. And there might be multiple source vertices because there might be multiple topological orderings and they might have different vertices at the beginning. Now which vertex is first in our topological ordering? It's the half vertex with the highest post order number. Therefore, the vertex with the highest post order number is guaranteed to be a source vertex. Similarly, the last vertex in our topological ordering must be a sink vertex, because edges can come into it but nothing can come out, otherwise it would be going right to left again. Therefore, the vertex with the lowest post order number is guaranteed to be a sink vertex. And once again, there might be multiple sink vertices. These might be multiple topological orderings with different vertices at the end. In this example, u and w are both sync vertices and only x is a source vertex. Now let's look at an alternative topological sorting algorithm. Now this algorithm is not going to be very useful for DAGs, but it is going to be very useful when we look at general directed graphs. Now we know in a topological ordering, the last vertex in the ordering is a sink vertex. So what can we do? We can find a sink vertex in some way. We can put it at the end of our list and then we can repeat on the remainder of the graph. So we're going to find a sink vertex, output it and then we're going to delete it from the graph and then we're going to repeat. Now we repeat this first step, find a sink, in this case maybe it's u, and then we find z, and we find y and we find x. Notice when x is the only vertex remaining, it's the sink vertex in that graph of size one. Finally, we're left with the empty graph and then we stop. What we've done is we outputed the vertices from the end to the beginning. And this gives us a valid topological sorting. Now how we actually find asink vertex is another question. But this algorithm, this basic approach is valid. And we're going to use this basic approach when we consider general directed graphs. And that's what we're going to turn our attention to now, general directed graphs, and we're going to look at the general question of what does this kind of activity mean in general directed graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c10479",
   "metadata": {},
   "source": [
    "## 264 Outline Review\n",
    "\n",
    "We've seen now how to find connected components in undirected graphs and how to topologically sort a DAG. Both of these algorithms involved one run of a vanilla version of DFS. Now let's look at general directed graphs. First we have to talk about what is the right analog of connected components for directed graphs. It turns out to be strongly connected components. And then we'll see an algorithm to find the strongly connected components of a general directed graph. Now the amazing aspect is, that we're going to find these strongly connected components with just two runs of the vanilla version of DFS. Let's dive into this algorithm and let's start by defining strongly connected components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3213515",
   "metadata": {},
   "source": [
    "## 265 Connectivity in Directed Graphs\n",
    "\n",
    "We're looking now at connectivity in directed graphs. So the remainder of the lecture we're going to be talking about directed graphs. First off, we have to talk about what is the correct notion of connectivity between a pair of vertices. So let us take a pair of vertices, V and W and we we'll say they're strongly connected. If there's a path from V to W and W to V. I have this vertex V and this vertex W and there's a path from V to W, it may pass through many vertices on the way and there's a path from W to V that may pass through many vertices along the way and these paths may intersect. So these vertices V and W are strongly connected. So instead of connected components in undirected graphs, the analog for directed graphs is going to be strongly connected components which we'll denote as SCC. Now an undirected graphs, the connected component is a maximal set of connected vertices. We keep adding in connected vertices as long as we can. For directed graphs, strongly connected components are the maximal set of strongly connected vertices. So we keep adding in strongly connected vertices as long as we can. Let's take a look at a specific example and mark the strongly connected components in the example to make sure everybody understands it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e445fa",
   "metadata": {},
   "source": [
    "## 266 SCC Quiz Question\n",
    "\n",
    "Here's a directed graph on 12 vertices. Let's go ahead and mark the strongly connected components in this graph, to make sure everybody understands the definition of SCCs. And then we can dive into some interesting properties of strongly connected points. First off, how many strongly connected components does this graph have? And now can you mark what are the strongly connected components in this graph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e878b6",
   "metadata": {},
   "source": [
    "## 267 SCC Quiz Solution\n",
    "\n",
    "In this graph, there are five strongly connected components. Let's go ahead and mark them. An easy one to notice is A by itself. Notice that from vertex A, I can reach many other vertices but no other vertices can reach A, so A is not strongly connected to any other vertices, therefore A is a strongly connected component by itself. These five vertices form a strongly connected component. Notice that all five vertices are strongly connected with each other, in particular, from vertex J, I can reach all of the other vertices and all the other vertices can reach vertex A via I. Similarly, these three vertices form a strongly connected component. These two vertices B and E form a strongly connected component and D is by itself because other vertices can reach D but D can't reach anybody else. So I have these five strongly connected components, A by itself, B and E, C, F, G, D by itself and then H, I, J, K, L are together. I want to point out some interesting properties of strongly connected components so I want to look at this graph on five vertices. I'm going to make a meta vertex for each strongly connected component. So when I have a meta vertex for A by itself, B and E together C, F, G, D and H through L. So I'm going to think of compressing each of these purple blobs into a vertex, a meta vertex and then there's going to be an edge from this meta vertex to this meta vertex because there is an edge from some vertex in C, F, G to some vertex in this strongly connected component namely from F to I and similarly there will be an edge between these meta vertices and these meta vertices and so on. So when we look at this graph on the meta vertices of strongly connected components we're going to see some interesting properties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29840fcd",
   "metadata": {},
   "source": [
    "## 268 Graph of SCC\n",
    "\n",
    "I want to look at the metagraph on strongly connected components. So we're going to have a vertex for each strongly connected component. So let's go ahead and mark the five strongly connected components, the five vertices in this metagraph. Here are the five strongly connected components, A, BE, D, CFG, and H through L. So I've marked those five vertices down here, A, BE, CFG, D, and H through L. Now, what are the edges in this metagraph? Well, some vertex in this component, BE, has an edge to some vertex in this component, CFG, namely B to C. So, we'll put an edge from this component to this component. Similarly, there's an edge from this component, BE, to D, from A to B, F to I, and E to L. Now, what do you notice about this graph? This metagraph on strongly connected components? Now, this metagraph on strongly connected components may, in fact, be a multigraph. For example, I may have an edge from G to J and then, I'll have another edge from this component to this component. So, I have a pair of edges from this component, C F G, to H through L. Now, the multiplicity doesn't matter. So we can keep those multiple edges or we can drop them. It doesn't matter. So let's go ahead and drop those multiple edges for simplicity. Either way, what is the key property of this metagraph on strongly connect components? What do you notice about this metagraph? Notice that there are no cycles. So, this metagraph is a DAG. And that's always the case. Every metagraph on strongly connected components for every directed graph is a DAG. Why is that? Why are there no cycles in this metagraph? Well, suppose there's two strongly connected components which are involved in a cycle. Then that means there's a path from somebody in this component to somebody in this component, and from somebody in this component, there's a path back to this component. Now, we know everybody in this component S is connected to each other because it's strongly connected. Everybody over here in S prime is strongly connected to each other. So, therefore if there's these paths from S to S prime and S prime to S, that means everybody in S can reach everybody in S prime and everybody in S prime can reach everybody in S. Therefore, S union, S prime is a strongly connected component. Now these components are defined to the maximal sets of strongly connected vertices. Therefore, we have a contradiction because a strongly connected component should be S union, S prime, it shouldn't be S separated from S prime. So, if there is a cycle in this metagraph, then we can merge strongly connected components together to get a larger strongly connected component and therefore we get a contradiction. Therefore, there can't be any cycles in this metagraph and thus it must be a DAG. We now have this amazing property. Every directed graph is a DAG of it's strongly connected components. So, we can break up a directed graph into strongly connected components and then we can order these strongly connected components into topological ordering because it's a DAG. So, you can take an arbitrary directed graph, which may be very complicated, and you can find this beautiful structure hidden in it. You can break it up into strongly connected components and then you can topologically sort these strongly connected components so that all edges go left to right. That's what we're going to do now. We're going to find an algorithm which is going to find the strongly connected components and it's going to find the strongly connected components in some order and the order is going to be topological ordering of these strongly connected components. So, we're going to topologically sort these strongly connected components as we find them. Now, the amazing thing is that we're going to find these strongly connected components and this topological ordering with just two runs of DFS. Now, let's dive into the algorithm to see how we're going to find these strongly connected components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296671cd",
   "metadata": {},
   "source": [
    "## 269 SCC Algorithm Idea\n",
    "\n",
    "Now, let's look at the main idea for our strongly connected component algorithm. Now, we're going to find these strongly connected components in topological ordering. So let's go back and look at our topological ordering algorithm for DAGs. Now, let's look at the topological ordering of a DAG where vertex V happens to be first and vertex W happens to be at the end. Now, what do we know about vertex W? We know it has to be a sink vertex. It might have some edges in but it can't have any edges out because those edges would go backwards in the ordering. Similarly, vertex V must be a source vertex. It can have edges out but it can't have any edges in. We have this alternative approach for topologically sorting a DAG. We could find a sink vertex, output it, rip it out, and repeat. Find a new sink in the resulting graph and repeat. Or, we could find a source vertex, put it at the beginning, rip it out of the graph, and repeat. Find a new source vertex in the resulting graph and so on. We can either work left to right, or right to left. Finding sink vertices and moving on, or finding source vertices and moving on. We're going to do a similar idea here but instead of finding a single vertex, we're going to find a sink strongly connected component. This is a component which is a sink vertex in a meta graph on strongly connected components. We're going to find a sink strongly connected component then we're going to output it. That's going to be at the end of our ordering. We're going to remove it from the graph, so we're going to remove all vertices from this strongly connected component from the graph and then we're going to repeat. We're going to find a sink component in this resulting graph, output it, remove it, and repeat until the graph is empty. Now, why do we do sink strongly connected components? Why not do source strongly connected components? For the topological ordering of the DAG, it didn't matter whether we started with sinks and worked that way backwards, or if we started with source and work forward. But for SCC it matters. Sinks are easier to work with. Why are sinks easier to deal with? Well, take any vertex which lies in a sink SCC. So S is a sink and strongly connected component, V is the vertex lying in that component. Now run Explorer from V. This is the basic procedure in the DFS algorithm. Suppose this is the first vertex that you explore from, which vertices do you visit when you explore from V? Well, take our earlier example where we had this sink strongly connected component which was H through L. Say we run explore from any of these vertices, what's going to happen when we run Explorer? We're going to visit all the vertices in this sink component but we're not going to visit any other components because we can't reach any other components from this component because it's a sink strongly connected component. So we visit all of this component and we visit nothing else. We don't see any other vertices, we just see this component itself. So if we can find a vertex which is guaranteed to be in a sink strongly connected component, then we can run Explorer from that vertex, and we're going to visit and we're going to find exactly that sink component. That's the key property about sink components. We just need to find a vertex which lies in that component, then when we explore from it, we're going to find the component itself and we're going to see nothing else. Therefore, we can mark all the vertices that we visited from this Explorer as lying in this sink component, then we can rip out those visited vertices and we can repeat the algorithm. Find a vertex in a sink of the resulting graph, run Explorer from it, mark those vertices as being in that component, and repeat. Now, what if we could find a vertex lying in the source component? For example, what if we can find vertex A? And we know that A is guaranteed to be in a source component, while in our earlier example, A happened to be a source component by itself. But suppose there are other vertices in this component and we want to figure out who are the other vertices in this component? When we run Explorer from vertex A, what happens? All we know is that from A we can reach many vertices. It's a source. So in fact, we can reach the whole graph from A. The whole graph is going to be visited. So we have no way of marking which vertices happen to be in this SCC and which vertices lie in other SCCs. But if we run Explorer from a vertex which lies in a sink SCC, we only visit that component and nothing else. That's the key property about sink components. Now, how can we find a vertex V which is guaranteed to lie in a sink component? That's our key task. Once we can find a vertex which is guaranteed to lie in a sink component, then we can run Explorer from that vertex, we'll find that sink component, rip it out, and repeat the algorithm. We'll find a sink component in the resulting graph, rip it out, repeat and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8d7cd8",
   "metadata": {},
   "source": [
    "## 270 Vertex in sink SCC\n",
    "\n",
    "So, in a DAG, the vertex with the lowest post order number is guaranteed to be a sink vertex. Now, let's look in a general directed graph, so there may be cycles. Still, let's run DFS on this general directed graph. Is there's some property by post ordering numbers so that we can find a vertex which is guaranteed to lie in a sink SCC? While drawing inspiration from DAGs, we may say, the vertex with the lowest post order number. Maybe that happens to be guaranteed to lie in a sink SCC. Now we might hope for the following property in general directed graphs. We might run DFS on this general directed graph and we might hope that the vertex with the lowest post order number always is guaranteed to lie in the sink SCC. If that was the case, then in order to find a vertex in a sink SCC, we just run DFS on this general directed graph, take the vertex with the lowest post order number, and that has the guaranteed property that we're looking for. Now, this guess follows from our inspiration from the topological sorting algorithm for DAG. Now does this hold? Is this property true? Unfortunately, it's not true. Here's an easy example where it's not true. I have a graph on three vertices, A, B, and C. Now, A and B are strongly connected with each other and C is by itself. Now, let's say I run DFS starting from vertex A. So, A's a root and then from A, I visit vertex B, then from B, I pop back to A and then I visit vertex C, and then I pop back to A. Now, what are the pre order and post order numbers? I start with A. Then I go to B. Then I finished B, pop back to A, go to C. Then I finish C and then I pop back to A. So, which vertex has the lowest post order number? It's vertex B. But, B lies in this strongly connected component. Is this a sink SCC? No. In fact, it's a source SCC. So, in this example, the vertex with the lowest post order number lies in a source SCC. Complete opposite of what we're hoping for. But what if instead of finding a sink SCC, I want to find a source SCC. I don't know how to use that, but let's just say I wanted to find a source SCC. Let's go back to look at our DAG algorithm. So, I want to find a source vertex. Remember in our topological sorting algorithm, the vertex at the beginning of the topological ordering is the vertex with the highest post order number. So, the vertex with the highest post order number is guaranteed to be a source vertex in a DAG. So, in the general directed graph, does the vertex with highest post order number always lie in a source SCC? Well, in this example, that's actually true. The vertex with highest post order number is A, which lies in a source SCC. It turns out that this property is true and we're going to prove that it's true. So, in every directed graph, when we run DFS on that directed graph, it doesn't matter on which vertex we start at and which is the ordering on the neighbors, for every directed graph, for every DFS run on that directed graph, the vertex with the highest post order number is guaranteed to lie in a source SCC. Now, let's use this property to get an SCC algorithm and then we'll go back and we'll prove that this holds. First off, how can we use it? We notice before that we need a vertex that lies in a sink SCC. If we have a vertex which lies in the source SCC, that's not useful for us. But all we can guarantee is to find a vertex which lies in a source SCC. We don't know how to find a vertex in a sink SCC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a055e5a",
   "metadata": {},
   "source": [
    "## 271 Finding sink SCC\n",
    "\n",
    "This is the property that we just claimed is true. When we run DFS on any directed graph, the vertex with the highest post order number lies in a source SCC. We'll go back and prove this property momentarily, but let's first use it to get an SCC algorithm. We need a vertex which lies in a sink SCC. How can we find such a vertex W which is guaranteed to lie in a sink SCC? Well, we know how to find a vertex which lies in a source SCC. I claim we can use this as a subroutine in order to find a vertex which is guaranteed to lie in a sink SCC. And then we're all done then we have our SCC algorithm. Why don't you go ahead and think about this? How can we find a vertex which is guaranteed to lie in a sink SCC using this property that the highest post order number lies in a source SCC? In some sense we just want to redefine the terms. We want to redefine a source to be a sink and a sink to be a source. What do we mean by that? Think about our topologically ordering of a DAG. The edges go left to right, and the beginning of the ordering is a source and at the end is a sink. What if we flipped all the edges to go backwards? Then this vertex which used to be a sink would now be a source, and this vertex which used to be a source will now be a sink because all the edges go right to left. So the ordering will be opposite. That's what we want to do now for our general directed graph. We want to flip the graph. We want to look at the opposite graph or the reverse graph. And then the source component will become a sink component, and the sink component will become a source component. Now, for a general directed graph G which has vertex set V, and edge set E. We're going to look at GR. This is going to be the reverse of the graph G. The vertex set is going to stay the same. The edge set is going to change from E to E-reversed. We're just going to reverse all the edges. These are directed edges so we're just going to look at the reverse edges. What exactly is E-R? For every edge in E, if we have an edge from V to W, we're going to add into E-R, we're going to add in the edge from W to V. E-R is simply the reverse of every edge in E. Notice if we flip all the edges, we look from G to G-R then all of the sources and sinks get flipped. Now, how does these strongly connected components of G compared to the strongly connected componentes of G-R? Notice that if a pair of vertices are strongly connected in G then they're also strongly connected in G-R There's a path from V to W and G, and a path from W to V. Then in G-R there also is a path from V to W and W to B. The set of strongly connected components are the same in the two graphs. Now, how is the meta graph on the strongly connected components? Look in these two graphs It might be different. In particular, the meta graph of strongly connected components in G is a DAG. And now, what does it look like in G-R? Well, we flipped that DAG so all the strongly connected components which were at the beginning of the topological ordering are now at the end. The edges are not going right to left instead of left to right. If we take a component which was a source SCC and G then it becomes a sink as SCC in G-R because the ordering goes backwards. Similarly, if we take a component which was at the end of the ordering for G then it's going to be at the beginning of the ordering for G-R. Now, how do we address our original problem? We want to find a vertex which is guaranteed to lie in a sink SCC of G. All we can do is find vertices which are guaranteed to lie in a source SCC. Well, the sink SCC of G corresponds to a source of G-R. So we take this input graph G, we construct its reverse graph, and then we run DFS on this reverse graph, and then we take the vertex with highest post order number as guaranteed to be in a source SCC of this graph G-R. This vertex which is guaranteed to be in a source SCC of G-R, or that SCC, is a sink in G. So this vertex with highest post order number for the DFS run on G-R is guaranteed to be in a sink SCC of G, the original graph. That's it. That's our algorithm for finding a vertex which is guaranteed to lie in a sink SCC of a graph G. You just reverse the graph, run DFS, take the highest post order number of vertex, and is guaranteed to be in a source of G-R, and therefore a sink of G. And now we have our algorithm for finding strongly connected components and is going to find the strongly connected components in topological ordering. We're going to find a sink SCC and move on, so we're going to find this ordering from right to left."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb98b8",
   "metadata": {},
   "source": [
    "## 272 SCC Example\n",
    "\n",
    "let's look back at our earlier example and now we can illustrate our algorithm for finding strongly connected components in this example here's our input graph G now this graph G had to sink strongly connected components D by itself and these five vertices formed a strongly connected component now our main observation from before was if we ran DFS starting from one of these vertices in the sink SEC so suppose we ran DFS starting from this vertex K well initially everybody's marked as unvisited we want we set K to be visited then we visit L I J and H and noticed no other vertices in the graph are visited so the only visited vertices are exactly this strongly connected component containing K so we can mark all the vertices that were visited so far as component 1 and then we can rip it out of the graph and we can look at the remainder of the graph and we can find a sink SCC and the remainder of the graph for example D will run explore from it will find this component then the remainder of the graph and we'll find one of these vertices or an explore from it find this component and continue that's how our algorithm is gonna work now how do we find this vertex in a sink SCC well to do that we look at the reverse graph here's the reverse graph it's got the same vertex set we simply flipped all the edges so this has an edge from B to D this has an edge from D to B now what we claimed is that if we run DFS on this graph of the reverse graph the vertex with the highest post number is gonna lie in a source SCC in this graph what are the source strongly connected components in this reverse graph it's these five vertices and D so the sink SEC is over here in the original input graph our source SCC is over here in the reverse graph the vertex with the highest post number is gonna lie in one of these source strongly connected components and therefore it lies in our sink SCC in the original graph so let's run DFS on this graph here's an example run of DFS on this reversed graph and I'll make arbitrary choices for the order on the vertices and on the neighbors so let's choose a vertex to start DFS from let's say we start from vertex C we'll give see pre-order number one and then from see we visit G and we give it pre-order number two then we go to F from F there's nobody left to explore so we give it its pre-order number and it's post order number only popped back up to G and so on let me skip ahead from C these are the vertices that we can visit we can see G F B a and E and this is one example of the DFS tree that we see and these are the preorder and postorder numbers that will get now DFS will continue to an unfitted vertex let's say D from D we can't get anywhere so it'll just stop I'll give it a preorder and postorder number then finally we'll get one of these five vertices starting from L this is the DFS tree we get for this component and here's the preorder and postorder numbers and notice the vertex with the highest post order number is vertex L which is in this source SCC well you may think well the go-to started at vertex C if he would have started at one of these vertices then the vertex with the highest post order number would not lie in this component but in fact if we would have started the DFS from one of these five vertices then who can be visited from that vertex well we can visit all this graph except for D so all these other vertices will be in the subtree say of L so they'll all get post order numbers which are smaller than L and then finally we'll go to D and D will be the last vertex visited it'll have the highest post order number so we'll still get a vertex with the highest post order number lying in a source SCC so let's take this vertex L it has the highest post order number in this DFS run that's the important property that we needed now later we're gonna explore all these vertices in this component and then we're gonna need the vertex with the highest post order number of the remaining vertices so in order to obtain that it'll be useful to have all these vertices sorted by their decreasing post order number so let's do that so this is a list of vertices of the original graph or the reverse graph sorted by decreasing post order number from this DFS run on the reverse graph and now we're done with the reverse graph and we can go back to our original graph here's our input graph once again now what are we gonna do we're gonna run DFS starting from this vertex L when we run from L who do we visit we visit i j k and h now as we visit these vertices let's cross them out to mark that they're visited and let's assign them a strongly connected component number so our mark these five vertices are strongly connected component number one now we need to continue DFS who do we want to continue from we want to look at this graph and we want to find a sink in this remaining graph so who are we gonna choose we're gonna choose the vertex with the highest post order number of the remaining vertices in this case it's D so we run DFS from D we Explorer from D D becomes visited and we mark it with component number two then we run from C we see these three vertices and we mark them with component number three then we take the highest post order number of the unvisited vertices B in this case we explore from B who do we see we see B and E that would be component 4 finally a that's component 5 valla we have our strongly connected components and the vertices are labeled by their strongly connected component number and one other very cool feature what do you notice about these strongly connected component numbers here are the five strongly connected components notice there's an edge from meta vertex 3 to meta vertex 1 from 4 to 1 and so on these are the rest of the edges in the meta graph now what do you notice about these edges they all go right to left so notice we've outputted these strongly connected ponens in Reverse topological order so it's quite amazing we've done two runs of DFS one on the reverse graph and one on the original graph and what we found are the strongly connected components of the original graph and we output it these strongly connected components in topological order or to be precise in Reverse topological order so we can take any directed graph a general directed graph and with two runs of DFS we can find it's strongly connected components and we can structure these strongly connected components in topological order let's formalize this algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6843494",
   "metadata": {},
   "source": [
    "## 273 SCC Algorithm Question\n",
    "\n",
    "Finally, let's detail our strongly connected component algorithm. The input to our algorithm is a directed graph G in adjacency list representation. The first step of our algorithm is to construct the reverse of the graph G. Then we run DFS on the reverse graph. What do we know? We know that the vertex with highest post order number from this DFS run is guaranteed to lie in a source SCC of GR, and therefore is in a sink SCC of G. So, now what we want to do is we want to run explorer from this vertex with highest post order number from this DFS run. So now, what we're going to do is we're going to order the vertices. These are the vertices of the original graph, G. We're going to order these vertices by decreasing post order number. This is like we're ordering them by topological ordering, as for our DAG algorithm, and these are the post order numbers from this DFS run. So, we run DFS on the reverse graph and then we order the vertices in the graph by decreasing post order number from this DFS run. Now, finally, we run DFS on the original graph, where the vertices are ordered by this decreasing post order number from this DFS run. Now, what is the version of DFS we use for this last one? We're actually going to use the undirected connected components algorithm. If you recall, that runs DFS and it marks the components that we see along the way with a connected component number CCnum. We're going to run that identical pseudocode. Even though this is a directed graph and that was designed for undirected graphs, we run the identical pseudocode and the components, the strongly connected components, in this case, are going to be numbered and they're going to be numbered in topological ordering. So, the first component is going to be at the end of our topological ordering and so on, and we're going to work over. Now, just to remind you, this is our pseudocode for our undirected connected component algorithm. So, this was just DFS where we kept track of the connected component number and we marked the vertices with their connected component number as we visited them. So, for step four of this directed SCC algorithm, we're going to run this identical pseudocode and this CCnum, is going to give us the ordering, the topological ordering on the strongly connected components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd644a3",
   "metadata": {},
   "source": [
    "## 275 Simpler Claim\n",
    "\n",
    "Here's a simpler claim once again. We have two components, two strongly connected components, S and S-prime. And there's some vertex in S, let's call it V. And there's a vertex in S-prime, let's call it W. And there's an edge from V to W. And the claim is that if we look at the maximum post-order number of all vertices lying in S compared to the maximum post-order number of all vertices lying in S-prime, then these maximum post-order number in S is bigger than the max post-order number in S-prime. So let's go ahead and prove that fact. Let's make one simple observation about this graph before we proceed. Notice we have an edge from this strongly connected component S to the strongly connected component S-prime. We know there's no cycles in this graph on strongly connected components, so there can't be a path from S-prime to S. Otherwise, these two strongly connected components would be a strongly connected component by itself. S union S-prime would be a strongly connected component and that would contradict the maximality of these SCCs. We know that there is no path from S-prime back to S because there's this edge that we assumed from V in S to W in S-prime. We're going to use this simple fact that there is no path from S-prime to S in the proof of this simpler claim. Run DFS on this graph and we're looking at the post-order numbers from this DFS run. Initially, all the vertices are unvisited. At some point some vertex in S Union S-prime must be visited. Let's take the vertex in S Union S-prime which is visited first and let's give it a name. Let's call it Z. We're going to have two cases. Either Z lies in S-prime or Z lies in S. Let's look at the first case. Let's say that Z lies in S-prime. Now, Z visits first so we're going to run Explore on Z. And who are we going to see? What vertices are we going to visit when we do Explore on Z? Well, which vertices are reachable from Z? Z lies in S-prime so from Z we can see all of S-prime but we can't see any of S. We see all of S-prime and we see none of S. All of S-prime is going to be visited and finished exploring, and none of S is going to be visited at all before we finish exploring from Z. Z and all of S-prime is going to be assigned post-order numbers before we even give a pre-order number for any vertex in S. The punchline is that all of the post-order numbers in S-prime. For every vertex in S-prime, its post-order number is strictly smaller than the post-order number of every vertex in S. Because we visit and finished exploring all the vertices in S-prime including Z before we even visit, before we even given a pre-order number to any vertex in S. And therefore, the maximum post-order number in an S-prime is strictly smaller than the minimum or the maximum post-order number in S which proves that claim. This completes the proof of the claim in this case where Z lies in S-prime. Now let's look at this case with a vertex Z lies in this component S. All these vertices in S and S-prime are unvisited. And now we visit Z and we start exploring from Z. Who do we reach? What vertices can we reach from Z? We can reach all of S because this is a strongly connected component, and we can reach all of S-prime because we can go from V over to S-prime, and then we can reach around S-prime. If we looked at the DFS tree, we're going to have this vertex Z. And what lies in that sub-tree? The rest of S Union S-prime lies in its sub-tree, in the DFS tree. Therefore, what do we know about Z? We know that Z is going to be the last vertex that we finish in S Union S-prime because it's the root of this sub-tree. We know that Z has the maximum post-order number of any vertex in S Union S-prime because it's the root of this sub-tree in the DFS tree. All the descendants have to be finished before we finished Z. And, therefore, since Z lies in S then we know that the vertex in S Union S-prime with maximum post-order number is Z which lies in S. So that proves the claim. The max post-order number in S, which corresponds to Z, is larger than anybody in S-prime. This completes the proof of this claim in this case where Z lies in S, and we also did the case where Z lies in S-prime. And that completes the proof of the simpler claim which also completes the proof of the key fact that the vertex with the highest post-order number lies in a source SCC. That completes the proof of correctness of our SCC algorithm and that's the end of our SCC algorithm description. It's quite an amazing fact. We can take any directed graph and we can compute its strongly connected components and we can topologically sort the strongly connected components. And we do it with just two runs of the vanilla DFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed16f8b",
   "metadata": {},
   "source": [
    "## 276 Proof of Key SCC Fact\n",
    "\n",
    "Now, we took the following fact for granted in the design of our algorithm. The vertex with the highest post order number lies in a source SCC. Now, let's prove that fact so that we complete the proof of correctness of our algorithm. Let's look at the following simpler claim. Let's take a pair of strongly connected components S and S prime. Now, if some vertex in S has an edge to some vertex in S prime, then what can we say about the post order numbers for S versus S prime? What we show is that the maximum post order number in S is greater, strictly greater than the maximum post order number in S prime. Now, what does this simpler claim give us? Well, this simpler claim gives us a way to topologically sort the strongly connected components. How do we topologically sort them? We sort them by the maximum post order number in that component. So, for each strongly connected component, we're going to look at the max post order number of the vertices lying in that component. So we can think of the post order number for this component to be the max over the vertices in that component of the post order numbers. Now, we sort these strongly connected components by their post order numbers and we sort them in decreasing post order number. And this claim, this simpler claim, tells us that all edges will go from larger post order number to smaller post order number. So, all edges will go left to right in the ordering of these strongly connected components. Now, what do we know about the vertex with the highest post order number? Well, it's strongly connected component is going to have the maximum, the largest of these max post order numbers. So, its component is going to be at the beginning of this topological ordering and it's guaranteed to be a source SCC, since it's at the beginning of the topological ordering. So, therefore, the vertex with the highest post order number will be in the component which is at the beginning of the topological ordering and therefore it's a source SCC. So, if we prove this simpler claim, then this gives us a way of topologically sorting the components by the max post order number. And this implies that the vertex with the highest post order number lies in a source SCC. So, if we prove this simpler claim, it implies the fact that we used in our SCC algorithm. So all we need to prove is this simpler claim and then we're done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f8f1fa",
   "metadata": {},
   "source": [
    "## 277 BFSDijkstras\n",
    "\n",
    "We've seen how to use the DFS algorithm to solve connectivity problems in undirected and directed graphs. Let's quickly remind you of some other common algorithms for exploring graphs. As opposed to DFS, which is depth first search, BFS is breadth first search. BFS explores the graph in layers. The input to the BFS algorithm is similar to the DFS algorithm. It's an undirected or directed graph G in adjacency list representation. But BFS has an additional input parameter. We specify a start vertex which we denote as little s. BFS returns the distance for every vertex from the start vertex little s. The graph G is unweighted, so the distance is defined as the minimum number edges to get from vertex s to vertex v. Now if there is no path from s to v, then this distance is defined as infinite. Now how do we get such a path of minimum length? Well, BFS also returns this previous array, which one can use to construct a path of minimum length from s to v. Now what's the running time of the BFS algorithm? BFS, like DFS, is linear time, so the running time is order n plus m, where n is the number of vertices in the graph G, and m is the number of edges in the graph G. Dijkstra's algorithm is a sort of more sophisticated version of BFS. It solves a similar problem as BFS, but instead, it considers a weighted version of the graph G. As in the BFS algorithm, the input to Dijkstra's algorithm is a graph G. It could be directed or undirected, and we have a specified start vertex, little s. But Dijkstra's algorithm has an additional input parameter. We were given a weight, a length for every edge, and this length has to be positive. What is the output of Dijkstra's algorithm? Well, it is the weighted analog of the BFS output, so it outputs this array dist and dist(v) is the length of the shortest path from s to v. Now one of the key requirements of Dijkstra's algorithm is that these edge lengths are positive. If you want to know how to deal with negative edge lengths, then you should refer to our dynamic programming lecture, DP3. Dijkstra's algorithm uses the BFS framework with the min-heap data structure. The min-heap data structure is often called the priority queue. Each operation in the min-heap data structure takes order log and time, so we get an additional log and factor on the BFS running time, and hence, the total runtime of Dijkstra's algorithm is order n plus m times logn. Now there are other variants of Dijkstra's algorithm with different data structures that they utilize. We'll always refer to the following the min-heap data structure in this class. And for concreteness, in this class we'll say the running time of Dijkstra's algorithm is order n plus m times logn. I assume that many of you have seen BFS and Dijkstra's many times in the past. If you need a quick review, I suggest you look at chapter four of the textbook."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
