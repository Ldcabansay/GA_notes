{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448f8860",
   "metadata": {},
   "source": [
    "# DP2 Knapsack Chain Multiply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532ab48",
   "metadata": {},
   "source": [
    "## 36 Knapsack Problem\n",
    "\n",
    "The next problem we're going to discuss is the knapsack problem. In this problem, the input is n objects. For each object were given its weight and its value. And we'll assume that the weights and the values are all integers. We'll denote the weights by w1 through wn and the values by v1 through vn. Now we're given one additional input parameter, which is the total capacity available, which will denote as capital B. Our goal is to find a subset of objects. We need the subset of objects to fit in the backpack. That means that their total weight is in most capital B. And we're trying to find the subset with maximum value, maximum total value. So let's try to restate this in more precise mathematical terms. What do we mean by the total weight is in most capital B. We want to look at those objects which are in our subset or chosen subset. So these are the i and s. We want to look at the weight of these. And we want to sum over the weight and we want that total weight to be in most capital B. The total value for a subset of objects is the sum over the objects and the subset of their individual values. And we're trying to maximize that sum. We're trying to find the subset of objects with maximum value, but maintaining that it fits in the backpack. So their total weight is in most, B. Let's summarize the problem one more time just to make sure everybody understands. So we're giving as input, the weights and values. These are these two n numbers, w1 through wn and the values v1 through vn. And we're also given the total capacity, capital B. Our goal is to find the subset of objects. So a subset of 1 through n, where that subset fits in the backpack. So the chosen subset has total weight at most capital B and the subset we chose has maximum total value. So we're trying to find the subset with maximum value, total value, and fits in the backpack. You can imagine some applications of this are, where we're scheduling jobs and we have limited resources or limited computation time and we want to choose the jobs with most value for us. But really, this is a nice toy example which is going to illustrate some different style dynamic programming solution. And then we're going to see many applications in the homework of some variants which use this style dynamic programming solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc13a0",
   "metadata": {},
   "source": [
    "## 37 Knapsack Problem Variants\n",
    "\n",
    "Now, there are two natural variants of this problem, and both have different dynamic programming solutions. So it'd be useful to look at both. In the first version, there's one copy of each object. So we're trying to find a subset without repetition. In the second version, there's unlimited supply of each object. So we can use an object as many times as we'd like. In this version, the subset S has repetition possibly. So the subset S is actually a multiset. To summarize, in the two versions of the problem, there is either unlimited supply of each object, so we can use it as many times as we'd like, or there's at most one copy of each object that we can use. We're going to start up by looking at version 1. So we have at most one copy of each object that we can use, and then we'll go back, and we'll look at the second version of the problem where we have unlimited supply of each object. So let's dive in and look at the first version and try to design an algorithm [inaudible]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72357ee",
   "metadata": {},
   "source": [
    "## 38 Greedy Algorithm Question\n",
    "\n",
    "Now if you are presented with this problem in real life, the first approach you might try is a Greedy approach. let's take a look at a specific example, and then this will highlight the pitfalls with the Greedy approach. Now here's an example with four objects. The values are 15, 10, eight and one. The weights are 15, 12, 10 and five. The total capacity will be 22. Now we're looking at the version where we have one copy of each object that we can use. Let's take a look and make sure that you understand the problem. What is the optimal solution for this problem? What does the subset of objects which attain the maximum value while fitting in the backpack?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409a15a6",
   "metadata": {},
   "source": [
    "## 39 Greedy Algorithm Solution\n",
    "\n",
    "For this example, the maximum value that we can obtain is 18, and that is obtained by using objects two and three. The total weight of these objects is 22,12 + 10 and the value we obtained from them, the total value is 10 + 8 is 18. Now, let's compare this to the greedy algorithm. What would a greedy approach do? A greedy approach would take the most valuable object and try to fill up the backpack as much as possible with that most valuable object. What is the most valuable object? That's not the one with the total maximum total value. It's instead the one with the maximum value per unit of weight. If the weights are in pounds or kilograms and the value is in dollars, then we're looking at the object with maximum to the other value per pound or per kilogram. In summary, the greedy approach would sort the objects by their value per unit of weight, which is this, quantity ri, which is states value divided by its weight. In this example the objects are already sorted by that ratio. We have that r1 > r2, > r3, > r4. So now what would a greedy approach do? The greedy approach would try to add object one, if it can, in this case it can, then we go to object two, and it would try to add object two if it can put. In this example, once you add in object one, you have 15 units of weight. You only have seven units of weight remaining, so you can no longer add in object two. Then we go to object three. The next most valuable object. We would try to add it in, does it fit? No it doesn't fit. Then we try to add object four, if it can. In this example it can because 15 + 5 is 20. It fits in the backpack so the greedy approach could obtain the solution using objects one and object four. Notice that the total value of this solution, object one and object four is 15 + 1, so it has total value 16, whereas our optimal solution has total value 18. This example illustrates why the greedy approach fails. It would try to add an object one, and once it does that, it's filling up the backpack too much and it can no longer fit in object two or three, and it ends up being more useful to skip object one and, instead, add in objects two and three. If you want to make a sub optimal choice at the beginning to allow you to squeeze in more objects later on. Now, let's go back and try to make our dynamic programming solution for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d340cd97",
   "metadata": {},
   "source": [
    "## 40 Knapsack No repetition\n",
    "\n",
    "Recall our basic recipe for designing a dynamic programming algorithm. The first step is always to define the sub-problem in words. Our first attempt is always to try the same problem on a prefix of the input. Therefore, we let K of I be the max value achievable using a subset of the first I objects. All we've changed is we've changed the set of objects available to us from the first N objects 1 through N to a subset of objects 1 through I. Our second step in our recipe for designing a dynamic programming algorithm is to find a recursive relation which expresses K of I the solution to the I sub-problem in terms of smaller sub-problems. In this case K 1 through K I minus 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5b5daa",
   "metadata": {},
   "source": [
    "## 41 Knapsack Recurrence 1\n",
    "\n",
    "To summarize, K of i is the max value we can obtain using a subset of the first i objects. And we're trying to find a recurrence which expresses K of i, the solution to the i's subproblem in terms of smaller subproblems. So let's go back and look at our earlier example and see if we get some idea for a recursive relation. In our earlier example, the objects had values 15, the object 1, 10, the object 2, 8 for object 3 and, 1 for object 4. And their weights were 15, 12, and 5. Now, let's look at this one dimensional table K that we're trying to find a recursive relation for. Now let's look at our one dimensional table K, in this example and see if we can figure out a recursive relation for the solutions of K of i in terms of smaller subproblems. So let's fill it in for this example. Let's start with K-1. In this case we're looking at a subset of object 1. So either we use object 1 or we use the empty set. Clearly using object 1 is better because it fits in a backpack and has total value 15. So K of 1 is 15. In this case. Now let's look at K of two, i equals two. In this case we're looking at a subset of objects 1 and 2. So either we use both objects in this case they have total weight 27. So they don't fit in the backpack so we can't use both objects. We can use either object 1 or object 2 or neither. And in this case in this example it's better to use object 1. Now let's go to i equals 3. What's the optimal solution for i equals 3. Well in this case we want to use objects 2 and 3. They have total weight 22. And this is our optimal solution to the entire problem as we saw before and that has total value which is a team. Now note this solution is obtained by using subsets 2 and 3 whereas our earlier subproblems, their solution was obtained by using object 1 only. Now the question is can we obtain this K of 3 which in this case is 18 using K of 1 and K of 2. But K of 3 is obtained by taking a sub optimal solution to i equals 2. We don't want to use the optimal solution because that doesn't allow us to add in object 3 into the backpack. There's not enough spare capacity available so we need to take a sub optimal solution to i equals 2. The key is that that sub optimal solution to i equals 2 has enough spare capacity to allow us to add in object 3. What we really want to do is we want to take the optimal solution to i equals 2 where the total capacity available is in most the total capacity in the original subproblem minus the weight from using object 3. If we're going to add object 3 to our solution then that takes weight W3. And then our capacity available goes down by W3. And we want to take the optimal solution to that smaller subproblem which is i equals 2 in this case and we want to look at the optimal solution with this capacity with the smaller capacity. In this case that capacity is 12. And if we take the optimal solution for i equals 2 with total capacity 12 than object 1 no longer fits and only object 2 fits in there. So the optimal solution will be just using object 2 and add the total value we obtain from that is 10. So this will have total value 10 and therefore we can append on object 3 onto it and we get the solution 2 and 3 and we get the total value 18. What we see from this example is that this definition of the subproblem does not suffice. We're not able to express K of 3 in terms of K-1 and K-2 because the solution to K of 3 does not y- build upon the solution to K- i equals 1 and 1 equals 2. Instead it uses a sub optimal solution 2, i equals 2. What is that suboptimal solution? That suboptimal solution has limited capacity available. It has limited capacity available in order to allow us to later add in object 3 and obtain a better solution for i equals 3. This points us in the right direction because what we need to do is limit the capacity available for these subproblems. So in some sense we want to take a prefix of the objects, 1 through i, and we want to take a prefix of the capacity available. This is going to lead us to our second attempt for the design of a dynamic programming algorithm for this problem. We're going to define the subproblems so that it considers a prefix of the objects and it varies the capacity available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb8ab0",
   "metadata": {},
   "source": [
    "## 42 Knapsack Subproblem 2\n",
    "\n",
    "Now, let's revise our subproblem definition trying to utilize some of the insight we just gained. Now, our initial attempt at a subproblem definition was k of i is the max value we can obtain using a subset of the first i objects. Now, the problem was when we tried to express K of i in terms of the earlier subproblems K1 through KI minus 1, it wasn't suffice to have the solution to Ki minus 1. But in fact what we needed was the solutions to the i minus first subproblem; we need the solution to the i minus first subproblem with the additional restriction that the total weight is no longer, at most, capital b, but its, at most, capital b minus the weight of the ith object. Because we're going to try to include the ith object and therefore, a weight available for the i minus first subproblem goes down. So this might be a sub optimal solution when the weight is capital b, but we need the optimal solution for this restricted weight. Therefore, what we're going to do is we're going to have two parameters; i and b. i is going to specify the prefix of the objects that we're going to consider. And little b is going to specify the total weight available. So then we're going to have a two dimensional table. Ok? Let's go ahead and formalize this. We're going to have two parameters,I and b as we just said. And i is going to be restricted between 0 and n, just as before. And little P is going to be restricted between 0 and capital b. And we're going to define the entry KIB. This is the entry in our two dimensional table to be the max value which we can obtain using a subset of objects 1 through i that's a prefix of the objects just as before. And the additional restriction is that the total weight is at most little b. Our goal in this problem is to compute the entry K, n, capital_B. This is the bottom right corner of this table. This corresponds to the max value which we can obtain using a subset of all n objects, n with total weight at most capital b. This is the original problem that we're trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfcfafe",
   "metadata": {},
   "source": [
    "## 43 Knapsack Recurrence 2\n",
    "\n",
    "Now, let's summarize the recurrence that we have. Now, a recurrence is going to have two scenarios. Either we include object i, or we don't include object i. First off, we have to know whether object i even fits in the backpack or not. If it doesn't fit, then we know we cannot exclude object i. So, we have to condition on whether the weight of the ith object, Wi, is smaller than b or not. If it is smaller than b, then the ith object can fit in the back pack. So, we're gonna take the best of the two scenarios, either including object i or not including object i. If we include object i, we gain value Vi, for object i, plus, we gain the value from the optimal solution to the subproblem which uses a subset of objects 1 through i-1 and has total capacity available b-Wi. The -Wi is because we included, we forced Wi and object i to be included in the backpack. The other scenario is that we don't include object i in the solution and then, the optimal solution to this subset of objects 1 though i is also going to be a subset of objects 1 through i-1, since object i is not being included. And the total capacity available, it stays the same. And we're going to take the best of these two scenarios, which means we're going to take the max of these two entries. In the other case, the weight of object i is strictly larger than b, and therefore it can't get included in the backpack. So then, our entry k(i, b) is just going to be the second scenario. This defines a recurrence, but to be complete, let's define the base cases and then we can go ahead and write the pseudo-code for our dynamic programming algorithm. For the first row of our table, then i=0. That means we're taking a subset of objects which are the empty set. We're taking a subset of the empty set. Therefore, there's no objects that can get included. So, the max value we can obtain is zero. Similarly, for the first column, we have total weight available, zero. Therefore, no objects can be included and therefore the max value we can obtain is, again, 0. Now, we can go ahead and write the pseudo-code for our algorithm, but let's take a look first at how we're going to do it. We have this table. It's a two dimensional table and we're going to fill this table row by row. And the point is, that when we fill the entry k(i, b), notice our recurrence, it always uses an entry from the previous row, either the entry right above is k(i-1, b) or an earlier entry in that previous row. So, if we filled the table row by row and the entries we need for the smaller subproblems for our recurrence will be there, already completed in the table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff2f87",
   "metadata": {},
   "source": [
    "## 44 Knapsack DP Pseudocode\n",
    "\n",
    "Now, let's write the pseudocode for our algorithm. We are solving the knapsack version where objects can get used in most once. So its the no repeat version of knapsack that we're solving. Now, the input to the algorithm are the weights for the N objects W1 through Wn, the values for the N objects, V1 through Vn, and the total capacity available capital B. Now let's start with the base cases which are going to be the first row in the first column of the table. For the first row of the table, as we mentioned before, the entries are all going to be zero because we have a subset of the empty set which we are using. The first column of the table, we have total capacity zero available. So once again, we have the max value is zero. Now let's fill the interior of the table and we'll do it row by row. So, we have a for loop where i varies from 1 to N. This will be the current row. And then we'll vary the parameter little b from 1 to capital B. This will bring us along the current row. To fill the entry K(i, b), we have to first check whether fits in the current capacity available which is little b. So, we need to check whether the weight of the ith object which is Wi is smaller than little b or not. If the weight is smaller, then we have two scenarios. We can either include object i, or we don't include object i, and we're going to take the best of those two scenarios. If we include object i, we gain value Vi4, and we gain the value from the optimal solution to a subset of the first i-1 objects, and with total capacity available B-Wi. Or if we don't include object i, we gain value K(i-1,b) which is the optimal solution, which is a subset of the first i-1 objects, with the same capacity available. And we are going to take the best of those two. So we're going to take the maxi of those two entries. And the other scenario where object i does not fit in the current capacity available, then we know that the entry K(i, b) is just the same as the previous row, K(i-1, b), since the optimal solution, since it doesn't include object i, will be a subset of the first i-1 objects. And finally, what is our algorithm going to return? It's going to return the bottom right entry of the table. This is the max value which we can obtain using a subset of objects 1 through N, and the total capacity capital B. This is our original problem that we're trying to solve, and that's the solution that we're trying to obtain. Now, we can go and look at the running time of our algorithm. We first have our base cases, the first for loop is over capital B entries, that's over the first row. That takes time, order capital B. Second for loop is over the first column, that's of size order N. Now we have our nested for loops which are going over the interior of the table. First one is of size order N, the second nested for loop is of size order Capital B. And then, within this nested for loops is an if-then-else statement which is going to be order one time. This is order one time. This one is order capital B. Our loop is of size order N. And so the total run time of these nested for loops is order N and times capital B. So, the total run time is order N times capital B. That completes the algorithm for the case where objects can be used at most once, and then we'll go back and we'll look at the solutions to the problem when we allow the object to be used multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d8c7c",
   "metadata": {},
   "source": [
    "## 45 Knapsack in Poly time Question\n",
    "\n",
    "The running time with the algorithm we just described as order n time capital b. The question I'd like to ask is that is an efficient algorithm or not? What do we mean by efficient? By efficient, we typically mean polynomial time. What do we mean by polynomial? We mean polynomial in the input size. So, is this running time of this algorithm that we just described is a polynomial in the input size? So I'll let you answer, yes or no? Is it polynomial in the input size, the running time of our argument we just described? And if it's no, I want you to detail exactly why is it not polynomial in the input size, and detail what exactly would it mean to be polynomial in the input size? What would be the requirement on the running time for it to be polynomial in the input size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b75b3cd",
   "metadata": {},
   "source": [
    "## 46 Knapsack in Poly time Solution\n",
    "\n",
    "Now, the answer is No. This running time is not polynomial in the input size. Why not? All right. This is a polynomial. I mean this is the polynomial in n capital B, but it's not a polynomial in the input size. Why not? The problem is this factor, capital B, if we wanna represent this number, capital B, it's just a number, right? How much space does it take to represent this number? The space required is the number of bits. What's the number of bits in capital B? It's log of capital B. So, the input to this problem is this number, capital B, and to represent his number, capital B is o to log B space. And so, the input size is o to log B. Now, of course, we also have n different numbers for the weights and the values. And those are gonna each take o to one bits for each of those numbers, and there's the o to n of those numbers for the two end weights and values. So, the input size is n and log B size. So, our goal is a running time which is polynomial in n and log B, whereas this is exponential in the input size. So, our running time is exponential in input size. Now, this is not surprising. Why not? What we're going to see is that knapsack is NP-complete. What does that mean? It might be that there is a polynomial time algorithm for this problem, but the fact is NP-complete means that, if we design a polynomial time algorithm for this problem, this Np-complete problem, then every problem in NP will have a polynomial time algorithm. So, it's unlikely that we're going to design a polynomial time algorithm for knapsack because that would imply polynomial time algorithm for a wealth of other problems. And many of them people have tried for many years, so it's unlikely that we're gonna design it right now with the simple dynamic programming algorithm. When we see this proof for this NP-completeness of the knapsack problem, it will be quite illuminating and you'll see why this algorithm is not efficient. Because what we'll do is we'll take a graph problem with n vertices, this will be a hard graph problem, and then we'll convert that into a knapsack problem. So, we reduce it to knapsack and we'll make a knapsack instance where this parameter capital B will be exponential in the graph size. So, this running time, where it will depends on capital B is polynomial, and capital B will give exponential running time for that original graph problem. And that will help it illustrate why this running time is exponential in the input size, whereas this is polynomial in the input size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8bdf5d",
   "metadata": {},
   "source": [
    "## 47 Knapsack Repetition\n",
    "\n",
    "Now, let's look at the other version of the knapsack problem. We gave a dynamic programming algorithm for the version of the problem where we have one copy of each object, so we can use each object at most, one time. Now, we'll look at the version of the problem where we have unlimited supply of every object. Here, we can use an object as many times as we'd like as opposed to the other version of the problem where we can use an object at most once. Now, let's go ahead with our recipe for designing a dynamic programming algorithm. The first step is to define the subproblem. And, let's go ahead and try the same subproblem as what we used for the other version of the problem and see if that works. Again, try to gain some insight. So, our subproblem for the previous version of knapsack was K(i,b) is the max value we can obtain using a subset of objects 1 through i with total weight, at most, little b. Now in this version, we're allowed to use objects multiple times. So instead of a subset where an object appears at most once, we're going to consider a multiset where an object can appear multiple times in the set. That's the only difference from the previous definition of the subproblem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b15aa0b",
   "metadata": {},
   "source": [
    "## 48 Knapsack2 Recurrence\n",
    "\n",
    "Now, let's go ahead and see if we can write a recurrence for this subproblem definition. So let's try to express K(i,b) in terms of smaller subproblems. We're going to try to use the insight that we had from the previous version of knapsack. So we're going to have two scenarios. Either we include object i or we don't include object i and we're going to take the best of those two so we're going to take the max. Now, as in the other version of knapsack, we're going to have two scenarios. In the other version of knapsack, we either included object i or we didn't include object i. In this version of the problem, we're going to have two scenarios. Either we include no more copies of object i or we're going to add in another copy of object i. Now, in the first scenario where we have no more copies of object i then the remainder of the set is going to be a subset or a multiset actually of objects 1 through i minus 1 with the total capacity available staying the same. Therefore the solution is k of i minus 1 B. Now in the other scenario where we're adding in another copy of object. And for that copy of object we get value v i. And in addition we get the optimal solution to this subproblem where the capacity went down by w i. So that capacity went down by w i. So the capacity available is now b minus w i. But notice here the first index is i, whereas in the other version of knapsack it was i minus 1 because in this version, we're allowed to use object i again even another copy, additional copies, whereas in the other version of knapsack once we use the object i which is what's happening in this case then we could no longer use object i. So this went down to i minus 1 to keep track that we didn't allow ourselves to use it multiple times. Now let's take a look. Is this recurrence in fact a valid recurrence? Are we expressing this current subproblem in terms of smaller subproblems? Previously, when we wrote recurrence for the current entry we always expressed it in terms of entries in previous rows. So this would be this one is in row i and the previous ones were in a row i minus 1. But in this case, we're actually using the same row. Let's look at the table. We're going to fill this table row by row and when we get to this entry, k i b, this current entry, okay, we've filled up the previous rows and we filled up this current row up to that entry. Now, what entries do does this recurrence require? Well, it requires the entry which is one row above. And in addition, it requires the entry which is in the same row but it's earlier in that row. So that will already be completed in the table. So these two entries that are acquired by this recurrence are already completed by the time we get to this current entry, k i b. So it's a valid recurrence that expresses k i b the current subproblem in terms of smaller subproblems. So we can go ahead and actually use the same pseudocode as before with the slightly different recurrence. Of course, we also have to condition on we have to make sure that the i object fits in the remainder remaining capacity. So we can only do this case when this holds. So if w i is the most b, then we take the best of these two scenarios. If w i is bigger than b then we can only use this case just as before and the other um pseudocode for the other version of knapsack. And what's our running time going to be? Well, we got a table of size n times b. That's the size of our table and to fill each entry it's going to take us order one time. So a running time is going to be order and times capital B just as before. So I won't go I won't detail it because it's almost the same pseudo code is for the other version of knapsack."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3364a1e1",
   "metadata": {},
   "source": [
    "## 49 Knapsack2 Recap\n",
    "\n",
    "Let's take a look at this algorithm for a moment. Often, when we get a solution which uses a two or three dimensional table, it's useful to look at it and see if we can simplify it to get a smaller table. And we might get a faster or less space or just a simpler solution. Okay? And that's what we're going to try to do here. So, look at our solution here. Now, why do we have this parameter i? The point of the parameter i in the original version of the knapsack problem, was to keep track of which objects we've considered or not. So, after we consider object i, then we can look at the first i minus 1 objects and look at a subset of those. But in this version of knapsack, we're allowed to use the object multiple times. So actually, it's not at all clear that we need to consider this parameter i. And in fact, we can get rid of it. So, let's write a new version of knapsack solution which, for this version, we're only going to have a single parameter. So, we'll just have a parameter for the weight available and we'll drop this parameter for the subset of objects that we consider."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f091a21",
   "metadata": {},
   "source": [
    "## 50 Knapsack2 Simpler Subproblem\n",
    "\n",
    "So, let's try to do our dynamic programming solution to this version of knapsack where we have a single parameter. The single parameter is going to be, little b, corresponding to the total weight available. And this little b is going to vary between the maximum capacity available, capital B, and zero. Now, we can define our subproblem. We define K(b) as the max value obtainable using total weight, at most, little b. And we allow ourselves to use a subset of all n objects or actually a multiset of all n objects, whereas, in the previous subproblem, we have an extra parameter i, and we only allowed ourselves to use a subset of the first i objects. I was trying to write a recurrence for this new subproblem definition. For the previous subproblem definition, in order to write a recurrence, we decided whether to include object i or not. Now, in this case, we don't have an object i, the last object. So, we want to try all possibilities for the last object to add. So, the recurrence for k of b is going to be, we're going to try all possibilities for the last object to add and we're going to take the best of those. How do we get the best? We take the max, and we'll use i to denote the last object that we're trying to add. So, last object that we're going at is going to be object i, and we'll consider all i between one and n. If we add in object i, we gain value, Vi. And in addition, we gain the optimal solution to the subproblem where the total weight goes down by Wi. This is expressed in K(b-Wi). And we're trying all possibilities for i between one and n. But we need that the ith object fits in the backpack. We can have this weight, this could possibly be a negative number. So, we need that Wi's and most little b. So, we're trying all possibilities for the last object to add where that last object can be anything between object one and object n, trying all these n objects. And, if that object fits in the current capacity, so Wi is smaller than Little b. We look at adding that objects. So, we gain value Vi4 and then our capacity available goes down by Wi. So, with the remaining capacity, we take the best solution. Now, since it's a one-dimensional table, be a straightforward to write the pseudo code. The table is one dimensional. There's not much choice in how we fill up the table. We're just going to fill it starting from K of 0 up to K of B. An this last entry is the solution to our problem. Let's go ahead and write the pseudo code for this algorithm just to detail it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a356f5",
   "metadata": {},
   "source": [
    "## 51 Knapsack2 Pseudocode\n",
    "\n",
    "So, here's a Pseudocode for our repeat solution for this version of knapsack. This is a knapsack version where we allow objects to be used multiple times. So, the repeat version of the knapsack. As before, the input to the problem are the weights of the n objects W1 through Wn, the values of the n objects V1 through Vn, and the total capacity available capital B. Now, it's a one-dimensional table so has no base case to worry about. And now, we're just going to go through that one-dimensional array from bottom up. Little b is going to be the index for our current position in the array. We start off by setting it equal to zero, in case there are no objects which fit in the current capacity available. Now, we go through each object and we consider that object as a last object to add it in the backpack. And we see if that gives us a better solution than anything we've obtained before. First, we need to check whether this object, object i, fits in the current capacity of (l,b). So, it's if Wi is, at most, little b. And now, if it is, we check whether this obtains a solution which is better than anything we've seen previously for this index. So, the previous best solution is K(b) and the new solution we obtain is Vi, for adding object i, plus the best solution for capacity (b-Wi) which is K(B-Wi). So, this is the solution we obtain now by using object i. And this is the previous best solution. So, if the new solution is better than the previous best, then we're going to update the current best. Now finally, we just returned the last entry of the table and that's our solution to our problem. That's the max value we can obtain using total weight, at most, capital B, which is the solution to the original problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d13f7c",
   "metadata": {},
   "source": [
    "## 52 Knapsack2 Running Time\n",
    "\n",
    "Finally, let's take a look at the writing time. We have this one for loop, which is a size order of capital B. Then, we have a nested for loop inside, it's of size order N. Each step, in this nested for loop, takes order one time. Therefore, the total run time is, order N times capital B. It's the same run-time as the original solution we had to this version. The space is smaller, and also it's simpler solution. It's a very simple algorithm, just a one dimensional table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ac76d8",
   "metadata": {},
   "source": [
    "## 53 Knapsack2 Traceback\n",
    "\n",
    "So, to output the actual multi-set, which obtains the optimal solution what we need to keep track of is, what is the last object we add in? What is the object I, which we add in, which obtains this optimal solution. In order to maintain that, we make a separate array, S. We initialize S(b)=0 corresponding to the empty set solution. And then when we update our current solution. So, when we get into this if then statement then we set S(b)=i corresponding to that the optimal solution for this subproblem is obtained by adding object I and then re-cursing on this smaller subproblem. Now, we can use this set S to backtrack. And, so, we can use it to produce a multi-set, which obtains the maximum value. The details of that backtracking are similar to what we did for longest common sub-sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03185a0d",
   "metadata": {},
   "source": [
    "## 54 Chain Matrix Multiply\n",
    "\n",
    "Our next dynamic programming problem is chain matrix multiply. This one will be a little different style from some of our early example. Actually, the solution will be a bit more complicated than the earlier examples that we looked at. So, let's look at a specific example so we can motivate this problem and then we'll go back and define the general problem. Our example will have four matrices A, B, C, D. Think of these matrices as having integer values for the entries. Our goal is to compute the product of these matrices A times B times C times D. And we'd like to do this in the most efficient manner possible. What exactly do we mean by most efficient? Let's look at a specific example. Let's say, A has of size 50 by 20, so it has 50 rows and 20 columns, B is of size 20 by one, C is of size 1 by 10, D is of size 10 by 100. Notice one thing, the number of columns of A has to match the number of rows of B. Also columns B has to match rows of C. Columns of C has to match rows of D. Why is that? When we multiply A x B, what we do is we take a row of A, this is A, and we take a column of B and we take the inner product. So we multiply entering and then we add it to the product of these, racks of these and so on. So the number of entries in this row has to equal the number entries in this column. And then we move onto the next row with the next column, next row with the next column. So this row has to have the same number of entries as this column. That's why columns here has to equal the number of rows here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1b66d3",
   "metadata": {},
   "source": [
    "## 55 Order of Operation\n",
    "\n",
    "Recall, our goal is to compute A x B x C x D. Now, matrix multiplication is associative. So, there are many ways to compute them. The standard ways to compute A x B. Take that product, x C, take that product, x D. But there are other things we can do. For instance, we can do A x B first, then we can do C x D second, and then we can multiply these two together. Or we can start with B x C, multiply that with A, and finally, multiply that with D. Or you start with C x D, multiply that with B, finally multiply that with A. Which of these is best? That's what we want to determine. Which is the best or what is the cost of the optimal parenthesization. In order to figure out which is the best or most efficient method for computing the product of these matrices, we need to assign a cost for each of these operations. So, let's take a look again at matrix multiplication and then we can figure out a reasonable notion of cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1232e88b",
   "metadata": {},
   "source": [
    "## 56 Cost for Matrix Multiply\n",
    "\n",
    "Let's take two matrices, w, and y, where w is of size a times b. So, it's got A rows and B columns. And Y is of size b time c. So, it's got the rows and c columns. And this will create the product of these matrices. So, we're looking at Z, which is W times Y. Now, note that Z is going to be of size a times c. It's going to have A rows, it's going to have the same number of rows as W and it's going to have C columns the same number of columns as Y. Now, let's look at the multiplication a little more carefully. Now, here's an example where we're multiplying W times Y, W has a lot of rows and a few columns, B columns. Similarly, Y has a few rows, it has B rows, and it's got a lot of columns, C. The product matrix, Z, is going to have A rows and C columns. Let's look at a specific entry Z, i, j. Row i. Column j. How do we get this entry? What we do is, we take row i from W and we take column j from Y and do the inner product of those entries. So, we move along the row and the column, K going from one to b and we take the Kth entry of this row times the Kth entry of this column. We multiply those together and then we take the sum of these b terms. So, to compute this one entry Z, i, j, it took us b multiplications and b-1 editions. Now, Z has a, c entries. So, in total, there will be a, c, b multiplications and there'll be roughly the same number of additions. So, therefore, we're going to say the cost of multiplying these matrices is a, b, c. Since these two terms are about the same and multiplications take longer than additions. So, this is a dominant factor. So, the cost of computing Z, the product matrix, W times Y is a, b, c where W has size a times b and Y has size b times c."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0802bb6",
   "metadata": {},
   "source": [
    "## 57 General Problem\n",
    "\n",
    "In the general problem, we have N matrices A1, A2, up to An. Our goal is to determine the minimum cost for computing the product of these N matrices. Now, the key parameter is the sizes of these matrices. So, we'll denote the size of the Aith matrix, Ai, as Mi-1 rows and Mi columns. So A1 will be of size M0 by M1. It has N0 rows and M1 columns. A2 will have M1 rows and M2 columns. So, the number of columns of A1 matches the number of rows of A2. Finally, the last Matrix has MN-1 rows and MN columns. All we need for this problem is the sizes of these matrices. We don't need to know the entries of the matrices given our cost. Our cost just depends on the sizes of matrices. Therefore, the input to the problem are these sizes. These N+1 parameters defining the sizes of these N matrices. And our goal is to find the minimum cost for computing the product of these N matrices. And we're just putting the minimum cost, if we can do that, then we can go back and figure out the parentheseszation, which realizes that minimum cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee79d3a",
   "metadata": {},
   "source": [
    "## 58 Graphical View\n",
    "\n",
    "To get some intuition for this problem, I want to look at an alternative representation of the problem and instead of looking at it as parenthesization we're going to represent it as a binary tree. Let's go back and look at our earlier example to see what we mean here. In our earlier example, we were looking at the product of four matrices, A times B times C times D. Now, the standard way of computing this was A times B and take that times C and then take that times D. Now we're going to represent this as a binary tree. The leaves of the trees are going to be the four matrices and the internal nodes are going to represent the intermediate computations. So, the root is going to represent the final computation, A times B times C times D. Now, for this parenthesization our first computation is A times B. So, we have the leaves for A and B and our first computation corresponds to the parent of those leaves, which corresponds to A Times B. Then, we take that matrix and multiply it by C. So, we have to leaf for C and then we have the parent of A times B and C, which corresponds to A times B times C. This internal node corresponds to A times B times C. How the subtree is structured tells us how the parenthesization is done for this subproblem. Finally, we take A times B times C and we multiply by D. So, this tree captures this parenthesization. Here's another parenthesization we can do A times B and we can do C times D and then we multiply those two together. This is represented by the following tree. We first compute A times B. Then we compute C times D. So, this represents A times B. This represents C times D. And then, we multiply those two together. This gives us our final matrix, A times B times C times D. So, the roots of these two trees represent the same product, A times B times C times D. How this subtree is structured tells us the parenthesization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d37c016",
   "metadata": {},
   "source": [
    "## 59 Chain Multiply Prefixes\n",
    "\n",
    "Now, let's go ahead and try to define our dynamic programming algorithm for this problem. The first step in our recipe is to define the subproblem in words and we'll always try prefixes as our first attempt. Therefore, we let c of i be the minimum cost for computing the product of the first i matrices in the input. Now, let's go back and see if we can define a recurrence for this subproblem definition. Let's look at our graphical view, our root, which we're trying to compute is A1 times A2 times up to An, the product of these n matrices. In our graphical view, we're going to have a left child and right child. The left child is going to correspond to some prefix. It's going to be the product of A1 times A2 up to Ai for some i. The right child is going to correspond to the product of Ai plus one up to An. Now, let's look at a recurrence which is going to tell us the minimum cost for computing A1 times A2 up through An. What we're going to do is we're going to try all possibilities for the split i and then we're going to recursively look up what is the minimal cost for computing this subtree, which has root A1 times A2 up to Ai. And we're going to look up, hopefully, recursively, what is the minimum cost for computing this subtree, which has a root A plus one through An. Now, we're aiming for prefixes, but this subproblem is a suffix. So, you might think, well, instead of just doing prefixes, why don't we just do prefixes and suffixes? Well, let's go one more level in this tree, in this binary tree and we'll see that it gets worse. Let's look at the children of this node. There's going to be some split here at some j, index j and the left's child is gonna correspond to the product of Ai plus one up to Aj and the right child is going to correspond to the product of Aj plus one up to An. Now, we'd like to try all possibilities for the split index j and then we'd like to look up in our table the minimum cost for this subtree and the minimum costs for this subtree. Well, this subtree is a suffix. That's good. But what is this tree? This is not a prefix or suffix. This is a substring. That's the key thing, is that all the intermediate computations are going to correspond to substrings. It's going to be some index i and some index j. And we're going to look at the product from i to j. And this is going to suffice to consider substrings. So, we're going to have to go back and revise our subproblem definitions, so that we don't consider prefixes, we're going to look at substring-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2467c340",
   "metadata": {},
   "source": [
    "## 60 Chain Multiply Substrings\n",
    "\n",
    "There's going to be two parameters, I and J. I is going to be the start of the substring, j is going to be the end of the substring. So, i is between j and one, and j is between i and n. And then we're going to define our subproblem as C(i,j) is going to be the minimum cost for computing the product of the matrices Ai through Aj. Now, let's try to write recurrence for C(i,j). Let's start with the base case. What is the easiest case to compute for C(i,j)? That's the case when i equals j. Then we're just computing Ai. So, the entry C(i,i ) what's the cost for? It's zero, because there's no work to be done. Let's look at our matrix actually, what are these base cases correspond to? Your matrix C and these are the diagonal entries. And notice, we're computing the entries where j is at least i. So, we're just trying to do this upper diagonal over here. We're not trying to compute this lower diagonal of the matrix. Now, let's try to do in general what the recurrence for C(i,j) is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907c4fb",
   "metadata": {},
   "source": [
    "## 61 Chain Multiply Recurrence\n",
    "\n",
    "We're trying to find recurrence for the entry C(i,j). This corresponds to computing the product of the matrices defined by the substring from i to j. Let's go back and look at our graphical representation. The root of the tree that we're trying to compute, corresponds to the product of the matrices Ai through Aj. Now, what are we trying to do? We're trying to find the split. Let's say at L and then the left subtree corresponds to the product of the matrices Ai through Al. The right subtree corresponds to the product of the matrices Al +1 through Aj. How is our recurrence going to work? We're going to try all possibilities for this index L for the split, and then we're going to look up in our table to minimum cost for computing this subtree, which corresponds to a smaller substring, and we're going to look up in our table the minimal costs for computing this subtree, and then we're going to combine those together. How much does it cost to combine them together? Well, this matrix is of size.Mi -1 by Ml, and this matrix is of size Ml by Mj. Sort of multiply these together it cost Mi -1 times Ml times Mj. So computing the root cause, this amount computing the left subtree costs, this entry corresponding to this substring which is C(i,l) and similarly, the right subtree corresponds to the entry Cl +1 j. So the total cost for this split at index L is the sum of these three. And what are we going to do? We're going to try all possibilities for L and we're going to take the one which has minimum sum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b370a96",
   "metadata": {},
   "source": [
    "## 62 Chain Multiply Summary\n",
    "\n",
    "Now, let's go ahead and write a recurrence for C(i,j). In our graphical view, this corresponds to the root of the tree which corresponds to Ai through Aj. We're going to try all possibilities for the split at index L and we're going to take the best of those. The best means minimum costs, so we're going to do a minimization over the choices of L and L is allowed to vary between i and j minus one. And we have this left subtree and this right subtree. The left subtree corresponds to Ai through Al. The right subtree corresponds to Ai plus one through Aj. The minimum cost for computing this left subtree is the entry C(i,l). The minimum costs for computing this right subtree is Cl plus 1j. Finally, we have to combine these together. Recall this product matrix is of size Mi minus one by Ml and this product matrix is of size Ml by Mj. To multiply these together, the cost is Mi minus one times Ml times Mj. Adding that term into our recurrence. We take the mean over the choices of L where L can vary from i to j minus one. And for that specific L, the cost is the cost for the left subtree C(i,l) plus the costs for the optimal right subtrees CL plus one j plus the cost of merging that left subtree with that right subtree which is Mi minus one times Ml times Mj. We take the sum of those three terms and we take the L which minimizes that sum some That's our recurrence for C(i,j)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cab278",
   "metadata": {},
   "source": [
    "## 63 Filling the Table\n",
    "\n",
    "Before we detail the Pseudocode for this dynamic programming algorithm, let's go back and look at our recurrence a little more carefully, and see how we're going to fill the table up. This recurrence is a little different from earlier examples, so how we're going to fill the table up is actually going to be a little bit more complicated than before. We're looking at this two-dimensional table C, and we're trying to compute the upper diagonal of this table. So those entries where j is at least i. Now, what was our base case? Our base case was diagonal, these are the entries C(i, i). This is the first thing we're going to fill in. What is the next thing that we're going to fill in? The next entries we're going to fill in are the entries C(i,i+1). Look at the recurrence for these entries. L is going to vary between i and that's it, that's the only choice for L. And then what are subproblems looks like? Our subproblems are C(i,i) and (i+1, i+1). So to compute this entry, we use these diagonal entries which are there in our base case. What is this? What are these entries correspond to in our table? These are the off diagonals, these are the second type of entries that we're going to fill in. So we're going to first do the diagonal and then we're going to do these off diagonal. And in order to compute the off diagonal, we use the diagonal entries. What is the next ones we're going to do? C(i,i+2). Look at the recurrence in order to compute these, we're going to use either diagonal entries or the off diagonal entries. So there are going to be there on the table. Finally, what is the last one we're going to compute? It's this one right here that corresponds to C(1,n) what is that? That's our final answer. That's the one we're trying to compute. This is the minimum cost to compute the product of matrices from A_1 up to A_n. So what our algorithm is going to do? It's going to start at this diagonal, and then it's going to move up, okay? How do we index that in our algorithm? Well, look. Look at this difference between the j and i. Let's call it the width and let's call that S. So S is j minus i. For the diagonal entries which are a base case, the width is S = 0. The off diagonals which we do next are have S = 1, they have width one, then we have width two, and so on until we get to width n-1. So we're going to vary the width from zero up to n-1. Now, we can go ahead and detail our Pseudocode for our dynamic programming algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9537c92",
   "metadata": {},
   "source": [
    "## 64 Chain Multiply DP Pseudocode\n",
    "\n",
    "Now, let's go ahead and detail the pseudocode for our dynamic programming algorithm to compute the minimum cost for multiplying these and matrices. Recall the input to the problem are the sizes. These n+1 numbers representing the sizes of the N matrices. M zero, M one, up to Mn. Let's start with the base case which corresponds to diagonal entering. The cost for these diagonal entries is zero since there's no computation to be done. Now, we're going to use our width parameter S. We already did the case where the width is zero. So we're going to start with one and go up two with n-1 which is our final solution. Then we have a parameter i which corresponds to the row. Notice that the rows are getting truncated at the end. Let's look at our matrix just to see what we mean by this. Our diagonal as these entries. And then, when we do the off diagonal, I'm going to start at this entry one, two and is going to end at this entry n-1. So it doesn't go down to the bottom row, okay? So that's why it stops at n-s. Once it tell you the index i and it tell you the width, then that defines the index j which is the end of the substring. Therefore, we let j, b, i + s. Now we're going to compute the entry c, i, j. We're going to take a min and we're going to vary over L and keep track of the current min so far. So we're going to initialize the min, the value, the current minimum to infinity. If using infinity makes you uncomfortable you can think of setting this to some huge number. Now, we're going to vary over the choices for the split at L. Recall L can vary between i and j -1. Now, for that split at L let's look at the cost, let's define a variable cur which is the current cost for the current index L. Because Mi -1 ml mj to combine the left and right subtrees. C(i,l) for the left subtree and C(l+1,j) for the right subtree. And we want to compare this to the current best. So the current best is larger than this value cur, then we're going to reset the current best to this current value. Then, the for loop. This is in this for loop, this is in this for loop. We have a bunch of nested for loops. Finally, what we return, our final answer is the top right of our matrix. We return this entry (C(1,n)) which corresponds to the cost, the minimum cost for computing the product of the matrices A1 through An. That completes our dynamic programming algorithm. Now let's take a look at the running time. We have this base case computation which takes order and time. Now, we have this first for loop which is of size order n. Then, we have another nested for loop which is the size at most n. And now we have another for loop which is of size at most n, again. And then within these for loops, it takes order one time for this computation. So we have three nested for loops of size order n each. So the total run time is order n q total time. So that completes our chain multiply dynamic programming algorithm. And the key thing here was that we, instead of using prefixes we had to move on to substrings for the subproblem definition. And then, how we filled in the table was a little bit more complicated. Usually, it's straightforward to fill in the table, we'd go row by row. But for this, when we were using substrings we have to go from the diagonal and then work our way up to the top right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05939b8",
   "metadata": {},
   "source": [
    "## 65 DP2 Practice Problems\n",
    "\n",
    "At this point you're prepared to approach any of the problems in chapter six of the textbook. But let me point out a few particular ones which are especially useful. Once again, these are problems from the desk Gupta Papademetriou Abaza Ronnie algorithms textbook and I'm using the numbering from the print version. Problem 6.17, problem 17 in chapter 6, is about change making. Given a set of coins, a set of denominations and a particular value, can you make change for that value using that set of denominations? In fact, there are three variants of the change making problem in the textbook. I suggest doing all three. Another good problem is problem 20 which is about building an optimal binary search tree. There's problem 7 which is about finding the longest palindrome subsequence, and you might also try the variant where instead of doing a palindrome subsequence you look for a palindrome substring. So they have to be contiguous. Now, to summarize some of what we learned in this lecture, when you're devising your subproblem, try prefixes first. If that doesn't work, you might be led in the direction of substrings. Now, one important note to keep in mind is that if you do use substrings and you get it to work and you get a valid solution, then I often go back and look at whether substrings were actually necessary or could I have simplified it and used prefixes. This might lead to a faster algorithm, but it's good to get a valid solution first. Get a polynomial time algorithm using substrings if necessary and then go back and check and think about whether actually substrings were required or not. It's better to have a correct algorithm which is a bit slower than an incorrect algorithm. Once again, the key for getting fluent in dynamic programming is to do lots of practice problems. There are a lot of practice problems in the textbook, but there are a lot available in the web too from other courses and from other books. Do as many as you can and at some point you'll get the hang of it and they'll feel easy. The solutions will start to seem similar to each other but the only way to get to that point is to do lots of practice problems. So good luck. I hope you start to enjoy it once you get."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
